{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M5uynwjvhrA"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3iq2bzpvhrG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage.segmentation import find_boundaries\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Torch libraries\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision.transforms import transforms\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ld5vGUnnIxh"
      },
      "outputs": [],
      "source": [
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNSBjD1SvhrH"
      },
      "source": [
        "## Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il4XeK0qvhrH"
      },
      "outputs": [],
      "source": [
        "seed_value = 42\n",
        "\n",
        "np.random.seed(seed_value)  # NumPy\n",
        "torch.manual_seed(seed_value)  # PyTorch CPU\n",
        "torch.cuda.manual_seed_all(seed_value)  # PyTorch GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF3GTE8GvhrH"
      },
      "source": [
        "# Data Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnZngh4G97il"
      },
      "outputs": [],
      "source": [
        "def equalise_image(image):\n",
        "   gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "   equalized_image = cv2.equalizeHist(gray_image)\n",
        "   equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "   return equalized_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJtHvioHxnP5"
      },
      "source": [
        "Defines a custom dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8OX-sjzxlq3"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "   def __init__(self, images, labels, transform=None):\n",
        "      self.images = images\n",
        "      self.labels = labels\n",
        "      self.transform = transform\n",
        "\n",
        "   def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "   def __getitem__(self, idx):\n",
        "      image = self.images[idx]\n",
        "      imageResize = cv2.resize(image, (299, 299))\n",
        "\n",
        "      label = self.labels[idx]\n",
        "      if self.transform:\n",
        "         imageResize = self.transform(imageResize)\n",
        "      return imageResize, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGxg8swexrTR"
      },
      "outputs": [],
      "source": [
        "def load_images_with_masks(image_directory, mask_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_filename in os.listdir(image_directory):\n",
        "        if image_filename.endswith(\".tif\"):\n",
        "            image_filepath = os.path.join(image_directory, image_filename)\n",
        "            mask_filename = image_filename + '.png'\n",
        "            mask_filepath = os.path.join(mask_directory, mask_filename)\n",
        "            try:\n",
        "                image = cv2.imread(image_filepath)\n",
        "\t\t\t\t        #Â image = equalise_image(image)\n",
        "                mask = cv2.imread(mask_filepath, cv2.IMREAD_GRAYSCALE)\n",
        "                images.append(image)\n",
        "                labels.append(mask)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {image_filename} or mask: {e}\")\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGo-igvExt7w"
      },
      "outputs": [],
      "source": [
        "def extract_subimages(images, labels, subimage_size=64, step_size=8):\n",
        "    subimages = []\n",
        "    sublabels = []\n",
        "    for i in range(len(images)):\n",
        "        image = images[i]\n",
        "        label = labels[i]\n",
        "        height, width = image.shape[:2]\n",
        "        for y in range(0, height - subimage_size + 1, step_size):\n",
        "            for x in range(0, width - subimage_size + 1, step_size):\n",
        "                subimage = image[y:y+subimage_size, x:x+subimage_size]\n",
        "                sublabel = label[y:y+subimage_size, x:x+subimage_size]\n",
        "                if np.all(sublabel == 0) or np.all(sublabel == 255):\n",
        "                    subimages.append(subimage)\n",
        "                    sublabels.append(sublabel[0][0])  # Assuming all values are the same in the sublabel\n",
        "    return np.array(subimages), np.array(sublabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApkBTSvsgGur"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "\n",
        "  image_directory = \"neuroendocrine_/images\"\n",
        "  mask_directory = \"neuroendocrine_/masks\"\n",
        "\n",
        "  images, labels = load_images_with_masks(image_directory, mask_directory)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3UHWDQzjrL8"
      },
      "outputs": [],
      "source": [
        "def load_train_data(images, labels, indexValidation, indexTesting):\n",
        "\n",
        "  mask = np.ones(len(images), dtype=bool)\n",
        "  mask[indexValidation] = False\n",
        "  mask[indexTesting] = False\n",
        "\n",
        "  train_images, train_labels = extract_subimages(images[mask], labels[mask])\n",
        "\n",
        "  del images\n",
        "\n",
        "  # labels should be 0 or 1\n",
        "  train_labels[train_labels == 255] = 1\n",
        "\n",
        "  print(\"Shape of the full train_images array:\", train_images.shape)\n",
        "  print(\"Shape of the full train_labels array:\", train_labels.shape)\n",
        "\n",
        "  return train_images, train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaGEgI_Ij_k6"
      },
      "outputs": [],
      "source": [
        "def get_indices(labels):\n",
        "\n",
        "  # Assuming train_images and train_labels are your training data\n",
        "  # Calculate the indices of each class\n",
        "  class_0_idxs = np.where(labels == 0)[0]\n",
        "  class_1_idxs = np.where(labels == 1)[0]\n",
        "\n",
        "  return class_0_idxs, class_1_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLZd0Wp4MRPY"
      },
      "outputs": [],
      "source": [
        "def setup_transforms(augment=False):\n",
        "\n",
        "  if augment == True:\n",
        "    transform = transforms.Compose([\n",
        "      transforms.ToPILImage(),\n",
        "      transforms.RandomHorizontalFlip(p=0.5),\n",
        "      transforms.RandomVerticalFlip(p=0.5),\n",
        "      transforms.RandomRotation(20),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "      ])\n",
        "  else:\n",
        "    transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "      ])\n",
        "\n",
        "  return transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-slcv5SWv9V"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(batch_size=100, size=\"balanced\", augment=False, val_idxs=[26, 27, 28], test_idx=29):\n",
        "\n",
        "  images, labels = load_data()\n",
        "\n",
        "  train_images, train_labels = load_train_data(images, labels, val_idxs, test_idx)\n",
        "\n",
        "  class_0_idxs, class_1_idxs = get_indices(train_labels)\n",
        "  print(f\"{len(class_0_idxs)} non-tumor images\")\n",
        "  print(f\"{len(class_1_idxs)} tumor images\")\n",
        "\n",
        "  del images, labels\n",
        "\n",
        "  transform = setup_transforms(augment)\n",
        "  sampler = None\n",
        "\n",
        "  if size == \"full\":\n",
        "\n",
        "    pass\n",
        "\n",
        "  elif size == \"balanced\":\n",
        "\n",
        "    minority_class_size = np.min([len(class_0_idxs), len(class_1_idxs)])\n",
        "\n",
        "    sel_class_0_idxs = np.random.choice(class_0_idxs, minority_class_size, replace=False)\n",
        "    sel_class_1_idxs = np.random.choice(class_1_idxs, minority_class_size, replace=False)\n",
        "\n",
        "    sel_idxs = np.concatenate([sel_class_0_idxs, sel_class_1_idxs])\n",
        "    np.random.shuffle(sel_idxs)\n",
        "\n",
        "    train_images = train_images[sel_idxs]\n",
        "    train_labels = train_labels[sel_idxs]\n",
        "\n",
        "  else:\n",
        "\n",
        "    class_0_idxs, class_1_idxs = get_indices(train_labels)\n",
        "    num_idxs = len(train_labels)\n",
        "    num_0_idxs = len(class_0_idxs)\n",
        "    num_1_idxs = len(class_1_idxs)\n",
        "\n",
        "    # Define weights for each sample\n",
        "    sample_weights = np.where(train_labels==0, num_idxs/num_0_idxs, num_idxs/num_1_idxs)\n",
        "\n",
        "    # Create a WeightedRandomSampler\n",
        "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=size, replacement=True)\n",
        "\n",
        "  del class_0_idxs, class_1_idxs\n",
        "\n",
        "  print(\"Shape of the selected train_images array:\", train_images.shape)\n",
        "  print(\"Shape of the selected train_labels array:\", train_labels.shape)\n",
        "\n",
        "  train_dataset = CustomDataset(train_images, train_labels, transform=transform)\n",
        "\n",
        "  del train_images\n",
        "  del train_labels\n",
        "\n",
        "  if sampler is None:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  else:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "\n",
        "  del train_dataset\n",
        "\n",
        "  print(f\"There are {len(train_loader)} mini-batches of {batch_size} samples.\")\n",
        "\n",
        "  return train_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmOA8GJZyfmY"
      },
      "outputs": [],
      "source": [
        "def get_images(dataset_path, test=False):\n",
        "\n",
        "   suff = None\n",
        "\n",
        "   if test == False:\n",
        "      suff = \"images\"\n",
        "   else:\n",
        "      suff = \"masks\"\n",
        "\n",
        "   images_dir_path = Path(f\"{dataset_path}/{suff}\")\n",
        "\n",
        "   # List all files in the folder\n",
        "   images_paths = sorted(list(images_dir_path.iterdir()))\n",
        "\n",
        "   return images_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNPD1m41vhrI"
      },
      "source": [
        "# Models Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxtbCQ2Pyrkh"
      },
      "outputs": [],
      "source": [
        "def import_model(model_name):\n",
        "  if model_name == \"inceptionv3\":\n",
        "    # Load InceptionV3 model pretrained on ImageNet\n",
        "    model = models.inception_v3(weights='DEFAULT')\n",
        "  elif model_name == \"AlexNet\":\n",
        "    # Load AlexNet model pretrained on ImageNet\n",
        "    model = models.alexnet(weights='DEFAULT')\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTEotK27ytTu"
      },
      "outputs": [],
      "source": [
        "def setup_model(model, device):\n",
        "  # Set the model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  num_classes = 2  # Assuming CustomDataset has a 'classes' attribute\n",
        "\n",
        "  if isinstance(model, models.inception.Inception3):\n",
        "    # Freeze all the parameters\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    # Modify the last layer to fit your number of classes\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(model.fc.in_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "  elif isinstance(model, models.AlexNet):\n",
        "    model.classifier.add_module('7', nn.ReLU())\n",
        "    model.classifier.add_module('8', nn.Linear(1000, 512))\n",
        "    model.classifier.add_module('9', nn.ReLU())\n",
        "    model.classifier.add_module('10', nn.Linear(512, 128))\n",
        "    model.classifier.add_module('11', nn.ReLU())\n",
        "    model.classifier.add_module('12', nn.Linear(128, 32))\n",
        "    model.classifier.add_module('13', nn.ReLU())\n",
        "    model.classifier.add_module('14', nn.Linear(32, 2))\n",
        "\n",
        "  # Move the model to the GPU\n",
        "  model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz3sEPY3zK4a"
      },
      "outputs": [],
      "source": [
        "def setup_training(model):\n",
        "\n",
        "\tif isinstance(model, models.inception.Inception3):\n",
        "\t\tmodel.fc.train()\n",
        "\n",
        "\telif isinstance(model, models.AlexNet):\n",
        "\t\tmodel.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkl7q5tUzvXU"
      },
      "source": [
        "###Â Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-UJCwwNy0Zn"
      },
      "outputs": [],
      "source": [
        "def training_loop(model, optimizer, loss_fn, train_dataloader, device,\n",
        "                  num_epochs, max_train, print_every, losses):\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader, 1):\n",
        "\n",
        "      # Fetch inputs and labels\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # Initialise gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Feedforward\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      loss.backward()\n",
        "\n",
        "      # Update parameters\n",
        "      optimizer.step()\n",
        "\n",
        "      # Append loss\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      # Print average loss every print_every iterations\n",
        "      if i % print_every == 0:\n",
        "        epoch_loss = running_loss / (print_every * len(inputs))\n",
        "        losses.append(epoch_loss)\n",
        "        print(f\"Iteration [{i}/{len(train_dataloader)}], Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "        running_loss = 0.0\n",
        "        print(\"------------------\")\n",
        "\n",
        "      # Iteration limit\n",
        "      if i >= max_train:\n",
        "        break\n",
        "\n",
        "    print(\"==========================\")\n",
        "\n",
        "  return losses\n",
        "\n",
        "# TODO move inside train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSVZnIKLzGMb"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loss_fn, dataloader, device,\n",
        "          num_epochs=1, max_train=200, print_every=10, losses=[]):\n",
        "\n",
        "  setup_training(model)\n",
        "\n",
        "  training_loop(model, optimizer, loss_fn, dataloader, device, num_epochs, max_train, print_every, losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tXu3CQt0ZwC"
      },
      "outputs": [],
      "source": [
        "def load_params(model, local_path, project_path, device):\n",
        "\n",
        "  model_path = None\n",
        "  params_path = None\n",
        "\n",
        "  if isinstance(model, models.inception.Inception3):\n",
        "\n",
        "    model_path = \"inception_v3\"\n",
        "    params_path = \"incv3_params.pth\"\n",
        "\n",
        "  elif isinstance(model, models.AlexNet):\n",
        "\n",
        "    model_path = \"AlexNet\"\n",
        "    params_path = \"AlexNet_params.pth\"\n",
        "\n",
        "  if os.path.exists(params_path):\n",
        "    full_path = f\"{local_path}/{params_path}\"\n",
        "    print(\"Params found in the runtime.\")\n",
        "  else:\n",
        "    raise Exception(\"No params in the runtime. Weights loading not succeeded!\")\n",
        "\n",
        "  # Load the saved dictionary into your model\n",
        "\n",
        "  state_dict = torch.load(full_path, map_location=device)\n",
        "  model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eflxc2RO0cRf"
      },
      "outputs": [],
      "source": [
        "def save_params(model, local_path):\n",
        "\n",
        "  params_path = None\n",
        "\n",
        "  if isinstance(model, models.inception.Inception3):\n",
        "    params_path = \"incv3_params.pth\"\n",
        "\n",
        "  elif isinstance(model, models.AlexNet):\n",
        "    params_path = \"AlexNet_params.pth\"\n",
        "\n",
        "  #Â Save the model state\n",
        "  torch.save(model.state_dict(), f\"{local_path}/{params_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtkmEDPa0p6J"
      },
      "outputs": [],
      "source": [
        "def predict(model, device, image):\n",
        "\n",
        "  testImage = image\n",
        "\n",
        "  subimage_size = 64\n",
        "  step_size = 8\n",
        "\n",
        "  height, width = testImage.shape[:2]\n",
        "  outputHeight = height - height % step_size\n",
        "  outputWidth = width - width % step_size\n",
        "  tumorCount = np.zeros((outputHeight, outputWidth))\n",
        "  count = np.zeros((outputHeight, outputWidth))\n",
        "\n",
        "  # Move model to GPU\n",
        "  model.eval()\n",
        "\n",
        "  for row in range(0, height - subimage_size + 1, step_size):\n",
        "    if row % 50 == 0:\n",
        "      print(f\"Row [{row}/{height}] computed\")\n",
        "    for col in range(0, width - subimage_size + 1, step_size):\n",
        "      subimage = testImage[row:row+subimage_size, col:col+subimage_size]\n",
        "\n",
        "      # Prepare subimage for InceptionV3\n",
        "      # Resize the subimage using OpenCV\n",
        "      resized_subimage = cv2.resize(subimage, (299, 299))\n",
        "\n",
        "      # Define the transformations\n",
        "      transform = transforms.Compose([\n",
        "          transforms.ToTensor(),  # Convert image to tensor\n",
        "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
        "          ])\n",
        "\n",
        "      # Apply the transformations and move to GPU\n",
        "      transformed_subimage = transform(resized_subimage).to(device)\n",
        "\n",
        "      # Compute output on GPU\n",
        "      with torch.no_grad():\n",
        "        output = model(transformed_subimage.unsqueeze(0))\n",
        "        label = torch.argmax(output)\n",
        "\n",
        "      # Write to matrix\n",
        "      if label == 1:\n",
        "        tumorCount[row:row+subimage_size, col:col+subimage_size] += 1\n",
        "      count[row:row+subimage_size, col:col+subimage_size] += 1\n",
        "\n",
        "  # Calculate average tumor occurrence per submatrix\n",
        "  avg = np.divide(tumorCount, count)\n",
        "\n",
        "  return avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol4Niv3jxzRH"
      },
      "source": [
        "## Custom Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9_Q8W-Cx1-1"
      },
      "outputs": [],
      "source": [
        "def focal_loss(alpha, gamma):\n",
        "\n",
        "  def _focal_loss(outputs, labels):\n",
        "\n",
        "    # Convert labels to int64 type\n",
        "    labels = labels.long()\n",
        "\n",
        "    # Compute class weights based on the frequency of each class in the labels\n",
        "    class_counts = torch.bincount(labels)\n",
        "\n",
        "    class_weights = (1 / class_counts.float()).clone().detach()\n",
        "\n",
        "    # Normalize the class weights\n",
        "    class_weights /= class_weights.sum()\n",
        "\n",
        "    # Compute softmax along the class dimension\n",
        "    input_softmax = F.softmax(outputs, dim=1)\n",
        "    # Gather the probabilities of the true class\n",
        "    p_t = torch.gather(input_softmax, 1, labels.view(-1, 1))\n",
        "    # Compute binary cross entropy loss\n",
        "    bce_loss = F.cross_entropy(outputs, labels, reduction='none')\n",
        "    # Compute focal loss\n",
        "    focal_loss = alpha * (1 - p_t) ** gamma * bce_loss\n",
        "    return torch.mean(focal_loss)\n",
        "\n",
        "  return _focal_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrEGsF4CvhrJ"
      },
      "source": [
        "# Evaluation Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIowM7w60sbW"
      },
      "outputs": [],
      "source": [
        "def get_pred(model, local_path, project_path, img_idx):\n",
        "\n",
        "  if isinstance(model, models.inception.Inception3):\n",
        "    model_name = \"inception_v3\"\n",
        "\n",
        "  elif isinstance(model, models.AlexNet):\n",
        "    model_name = \"AlexNet\"\n",
        "\n",
        "  if os.path.exists(f\"avg_{img_idx}.png\"):\n",
        "    avg_path = f\"{local_path}/avg_{img_idx}.png\"\n",
        "    print(\"avg image found in the runtime.\")\n",
        "  else:\n",
        "    raise Exception(\"An chosen avg has not been found!\")\n",
        "\n",
        "  avg = cv2.imread(avg_path)\n",
        "\n",
        "  # Convert the image to grayscale\n",
        "  avg = cv2.cvtColor(avg, cv2.COLOR_BGR2GRAY)\n",
        "  avg = avg/255\n",
        "\n",
        "  return avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuChMsac0tr1"
      },
      "outputs": [],
      "source": [
        "def beautify_output(avg):\n",
        "  printAvg = avg*255\n",
        "  return printAvg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgxzeKvX0vah"
      },
      "outputs": [],
      "source": [
        "def threshold_output(avg, thr=0.5):\n",
        "  modelGuess = np.where(avg >= thr, 255, 0).astype(np.uint8)[:1283, :2040]\n",
        "  return modelGuess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SujDwKgD0yBq"
      },
      "outputs": [],
      "source": [
        "def visualise_output(printable):\n",
        "  # Displaying the numpy array as grayscale\n",
        "  plt.imshow(printable, cmap='gray', vmin=0, vmax=255)  # Specify vmin and vmax\n",
        "  plt.axis('off')  # Turn off axis\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd9c4RDXvSn6"
      },
      "outputs": [],
      "source": [
        "def save_pred(avg, img_idx):\n",
        "  if avg is not None:\n",
        "    cv2.imwrite(f'avg_{img_idx}.png', avg)\n",
        "  else:\n",
        "    print(\"No avg has been provided. Saving not succeeded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc180reCvhrJ"
      },
      "outputs": [],
      "source": [
        "def save_thr_pred(thr_pred, img_idx):\n",
        "  if thr_pred is not None:\n",
        "    cv2.imwrite(f'pred_image_{img_idx}.png', thr_pred)\n",
        "  else:\n",
        "    print(\"No thr_pred has been provided. Saving not succeeded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-76yXBZayOqc"
      },
      "outputs": [],
      "source": [
        "def visualise_comparison(thr_output, testMask):\n",
        "\n",
        "\tcombined_matrix = 2 * thr_output/255 + testMask[:,:,0]/255\n",
        "\n",
        "\t# Define colors for each case\n",
        "\tcolors = ['black', 'green', 'red', 'white']\n",
        "\tcolor_labels = ['correct non tumor', 'false positive', 'false negative', 'correct tumor']\n",
        "\n",
        "\t# Plot the combined matrix\n",
        "\tplt.figure(figsize=(10, 8))\n",
        "\tplt.imshow(combined_matrix, cmap=plt.cm.colors.ListedColormap(colors))\n",
        "\n",
        "\t# Create a separate legend outside the plot\n",
        "\tlegend_handles = [plt.Rectangle((0,0),1,1, color=color) for color in colors]\n",
        "\tplt.legend(legend_handles, color_labels, loc='upper left', bbox_to_anchor=(1, 1), facecolor='dimgrey')\n",
        "\n",
        "\tplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LAK_Wrv1JZQ"
      },
      "outputs": [],
      "source": [
        "def pixel_accuracy(y_true, y_pred):\n",
        "\n",
        "  return accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "\n",
        "def pixel_precision(y_true, y_pred): # REMOVED IN FULLY-TUMOR IMAGES\n",
        "\n",
        "  true_positives = np.sum(np.logical_and(y_true, y_pred))\n",
        "  false_positives = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
        "\n",
        "  if not False in y_true: return None\n",
        "  # if all targets are positive, there cannot be false_positive,\n",
        "  # then the PPV is trivially 0 (uninformative)\n",
        "\n",
        "  if true_positives + false_positives == 0:\n",
        "    return None\n",
        "  else:\n",
        "    return true_positives / (true_positives + false_positives)\n",
        "\n",
        "def pixel_sensitivity(y_true, y_pred): # Also known as RECALL\n",
        "\n",
        "  true_positives = np.sum(np.logical_and(y_true, y_pred))\n",
        "  false_negatives = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
        "\n",
        "  if true_positives + false_negatives == 0:\n",
        "    return None\n",
        "  else:\n",
        "    return true_positives / (true_positives + false_negatives)\n",
        "\n",
        "def pixel_specificity(y_true, y_pred): #Â REMOVED IN FULLY-TUMOR IMAGES\n",
        "\ttrue_negatives = np.sum(np.logical_and(np.logical_not(y_true), np.logical_not(y_pred)))\n",
        "\tfalse_positives = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
        "\n",
        "\tif true_negatives + false_positives == 0:\n",
        "\t\treturn None\n",
        "\telse:\n",
        "\t\treturn true_negatives / (true_negatives + false_positives)\n",
        "\n",
        "\n",
        "def intersection_over_union(y_true, y_pred):\n",
        "\n",
        "  intersection = np.logical_and(y_true, y_pred)\n",
        "  union = np.logical_or(y_true, y_pred)\n",
        "  return np.sum(intersection) / np.sum(union)\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "\n",
        "  intersection = np.logical_and(y_true, y_pred)\n",
        "\n",
        "  return 2.0 * np.sum(intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
        "\n",
        "def f1_score(y_true, y_pred): # REMOVED IN FULLY-TUMOR IMAGES\n",
        "\tprecision = pixel_precision(y_true, y_pred)\n",
        "\trecall = pixel_specificity(y_true, y_pred)\n",
        "\n",
        "\tif precision is None or recall is None:\n",
        "\t\treturn None\n",
        "\telse:\n",
        "\t\treturn 2.0 * (precision * recall) / (precision + recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9vBqrED1LEA"
      },
      "outputs": [],
      "source": [
        "def get_true_labels(mask, tumor=True):\n",
        "  y_true = (mask[:,:,0]/255).astype(bool)\n",
        "\n",
        "  if tumor == False:\n",
        "    y_true = np.logical_not(y_true)\n",
        "\n",
        "  return y_true\n",
        "\n",
        "def get_pred_labels(mask, tumor=True):\n",
        "  y_pred = (mask/255).astype(bool)\n",
        "\n",
        "  if tumor == False:\n",
        "    y_pred = np.logical_not(y_pred)\n",
        "\n",
        "  return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAYfY0XW9KxM"
      },
      "outputs": [],
      "source": [
        "def format_images_grid(images, titles, columns=2, cmap=\"gray\"):\n",
        "\n",
        "  num_images = len(images)\n",
        "\n",
        "  columns = min(columns, num_images)\n",
        "  rows = math.ceil(num_images / columns)\n",
        "\n",
        "  fig, axs = plt.subplots(rows, columns, figsize=(11*rows, 8*columns))\n",
        "\n",
        "  if type(axs) is not np.ndarray:\n",
        "    axs = np.array([axs])\n",
        "\n",
        "  for i, ax in enumerate(axs.flat):\n",
        "      if i < num_images:\n",
        "          ax.imshow(images[i], cmap=cmap)\n",
        "          title = titles[i]\n",
        "          ax.set_title(title)\n",
        "      else:\n",
        "          ax.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU6JFszPy7Dw"
      },
      "outputs": [],
      "source": [
        "def get_comparison_images(thr_avgs, masks):\n",
        "\n",
        "  comp_images = []\n",
        "\n",
        "  for i in range(len(masks)):\n",
        "\n",
        "    mask = masks[i]\n",
        "    thr_avg = thr_avgs[i]\n",
        "\n",
        "    combined_matrix = 2*thr_avg/255 + mask[:,:,0]/255\n",
        "\n",
        "    comp_images.append(combined_matrix)\n",
        "\n",
        "  return comp_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToXmdIA4zGt0"
      },
      "outputs": [],
      "source": [
        "def visualise_comparison_legend(legend_handles, color_labels):\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(0.1, 0.1))  # Create a very small figure\n",
        "  ax.legend(legend_handles, color_labels, loc='upper right', facecolor='dimgrey')\n",
        "  # Hide other figure elements (optional)\n",
        "  ax.axis('off')  # Turn off axes\n",
        "  fig.patch.set_alpha(0)\n",
        "  plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMbyoNWgzRvY"
      },
      "outputs": [],
      "source": [
        "def get_metrics_row_df(y_true, y_pred):\n",
        "\n",
        "  acc = pixel_accuracy(y_true, y_pred)\n",
        "  prec = pixel_precision(y_true, y_pred)\n",
        "  spec = pixel_specificity(y_true, y_pred)\n",
        "  sens = pixel_sensitivity(y_true, y_pred)\n",
        "  iou = intersection_over_union(y_true, y_pred)\n",
        "  dice = dice_coefficient(y_true, y_pred)\n",
        "  f1_sc = f1_score(y_true, y_pred)\n",
        "\n",
        "  # Define sample data\n",
        "  row_to_append = [\n",
        "      acc, prec, spec, sens, iou, dice, f1_sc\n",
        "  ]\n",
        "\n",
        "  return pd.DataFrame(row_to_append, index=columns).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLGYgI7UvhrK"
      },
      "outputs": [],
      "source": [
        "def conf_matrix(y_true, y_pred, normalise=None):\n",
        "\n",
        "  conf_matrix = confusion_matrix(y_true.flatten(), y_pred.flatten(), normalize=normalise)\n",
        "  return conf_matrix\n",
        "\n",
        "def format_conf_matrices(idx, conf_matrix, conf_norm_matrix):\n",
        "\n",
        "  fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
        "\n",
        "  fig.suptitle(f'idx {idx}', fontsize=14, fontweight='bold')\n",
        "\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5, square=True, ax=axs[0])\n",
        "  axs[0].set_title(\"Confusion matrix\")\n",
        "  axs[0].set_xlabel(\"Predicted label\")\n",
        "  axs[0].set_ylabel(\"True label\")\n",
        "\n",
        "  sns.heatmap(conf_norm_matrix, annot=True, fmt=\".2%\", cmap=\"Blues\", linewidths=.5, square=True, ax=axs[1])\n",
        "  axs[1].set_title(\"Confusion normalised matrix\")\n",
        "  axs[1].set_xlabel(\"Predicted label\")\n",
        "  axs[1].set_ylabel(\"True label\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6nSB1t51PRB"
      },
      "outputs": [],
      "source": [
        "def visualize_bordered_mask(testImage, modelGuess, radius):\n",
        "  # Define the disk structuring element\n",
        "  radius = 2\n",
        "  disk_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "\n",
        "  # Apply erosion using the disk structuring element\n",
        "  eroded_mask = cv2.erode(modelGuess, disk_kernel)\n",
        "\n",
        "  tumorBorder = modelGuess - eroded_mask\n",
        "\n",
        "  map_rgb = cv2.cvtColor(tumorBorder, cv2.COLOR_GRAY2RGB)\n",
        "  alpha = 0.5  # Adjust the transparency of the overlaid image\n",
        "  overlay = cv2.addWeighted(testImage[:1283, :2040], alpha, map_rgb, 1 - alpha, 0)\n",
        "\n",
        "  plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1ehzDrizBPY"
      },
      "source": [
        "# Notebook Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8coyziazUbu"
      },
      "source": [
        "## Training Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0TPK9TlzTJF"
      },
      "outputs": [],
      "source": [
        "load = False\n",
        "training = True\n",
        "save = True # regardless of the actual training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6k4mzTUzX8M"
      },
      "source": [
        "## Validation Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV1LNtX7zlKT"
      },
      "outputs": [],
      "source": [
        "val_compute = True # If true, compute the mask prediction of a chosen image; otherwise, consider the already pre-computed prediction.\n",
        "val_avg_write = True\n",
        "val_conf_matr_write = True # Write the confusion matrices figure to Colab.\n",
        "val_output_write = False # Write the final output photo to Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Aj-IogOk8nz"
      },
      "source": [
        "## Testing Control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgXAt2Vvk9_d"
      },
      "outputs": [],
      "source": [
        "test_compute = False # If true, compute the mask prediction of a chosen image; otherwise, consider the already pre-computed prediction.\n",
        "test_avg_write = False\n",
        "test_conf_matr_write = False # Write the confusion matrices figure to Colab.\n",
        "test_output_write = False # Write the final output photo to Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTrFF0S_ssAY"
      },
      "source": [
        "# Resources Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x61WbR9tssAZ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Luca-Olivieri/NAML_project.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfp6Sv5TssAa"
      },
      "source": [
        "### Resources paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixBHnuqissAW"
      },
      "outputs": [],
      "source": [
        "local_path = \"/content/\"\n",
        "project_path = local_path+\"NAML_project\"\n",
        "dataset_path = local_path+\"neuroendocrine_\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0NaXTwvssAb"
      },
      "source": [
        "# Model Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1fezVKNssAb"
      },
      "source": [
        "Import one of the pre-trained models.\n",
        "\n",
        "Available models:\n",
        "\n",
        "- Inception v3\n",
        "- AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcWGs8jjssAb"
      },
      "outputs": [],
      "source": [
        "# model_name = \"inceptionv3\"\n",
        "model_name = \"AlexNet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ_N3B_JssAb"
      },
      "source": [
        "Select version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyKylxe-ssAc"
      },
      "outputs": [],
      "source": [
        "model = import_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XoKJaYtJiL2"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBJ7oy1VuqQM"
      },
      "outputs": [],
      "source": [
        "setup_model(model, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5eOBHuZssAc"
      },
      "source": [
        "# Data Ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbuA17mWssAc"
      },
      "source": [
        "Download dataset from GitHub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljz2R5XZssAc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cialab/neuroendocrine_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpV7IEN1MWQO"
      },
      "outputs": [],
      "source": [
        "images_paths = get_images(dataset_path, test=False)\n",
        "masks_paths = get_images(dataset_path, test=True)\n",
        "print(np.array(images_paths))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--tMA9qRt8z5"
      },
      "source": [
        "# Validation and Testing Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thNYtKpQyP2d"
      },
      "outputs": [],
      "source": [
        "val_idxs = [0, 1, 2] #Â 23, 25, 26 are full-white images\n",
        "test_idx = 29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewhUkvWebf9T"
      },
      "outputs": [],
      "source": [
        "for i, path in enumerate(masks_paths):\n",
        "\n",
        "  symbol = \"Training\"\n",
        "\n",
        "  if i in val_idxs: symbol = \"VALIDATION\"\n",
        "  elif i == test_idx: symbol = \"TESTING\"\n",
        "\n",
        "  print(f\"[{i:0>2} | {symbol}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9kdRRjiOEsd"
      },
      "source": [
        "# Parameters Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB9rrLAAOOh8"
      },
      "outputs": [],
      "source": [
        "if load == True:\n",
        "\n",
        "\t# Load parameters from runtime\n",
        "\tload_params(model, local_path, project_path, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVn-m3lZssAd"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJYbbnFz3eta"
      },
      "source": [
        "## Train Dataloader Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgKdeXHc774c"
      },
      "outputs": [],
      "source": [
        "if training == True:\n",
        "\n",
        "  # size = \"balanced\", \"full\", [INTEGER]\n",
        "\n",
        "  train_loader = create_dataloader(batch_size=100,\n",
        "                                   size=\"balanced\",\n",
        "                                   augment=False,\n",
        "                                   val_idxs=val_idxs, test_idx=test_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itl5Kqld1D_T"
      },
      "source": [
        "Choose the optimiser:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am8WYRcC1Cgg"
      },
      "outputs": [],
      "source": [
        "#Â optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "# optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XA_RFGH1HNk"
      },
      "source": [
        "Choose the loss function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NEdNbgp1Ivw"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#Â loss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1, 1], dtype=torch.float).to(device))\n",
        "# loss_fn = focal_loss(alpha=1, gamma=2) # alpha = 1/(1+w_0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "205BwbVe3oMw"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKmjDX4q9dhd"
      },
      "outputs": [],
      "source": [
        "if training == True:\n",
        "\n",
        "\tlosses = []\n",
        "\n",
        "\t# Proceed with the training loop\n",
        "\ttrain(model, optimizer, loss_fn, train_loader, device,\n",
        "\t\t\t\t\t\t\t\tnum_epochs=5, max_train=1e8, print_every=10, losses=losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMw_d-ch3qq0"
      },
      "source": [
        "### Training Loss Trend Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIv3XxV5z7d7"
      },
      "outputs": [],
      "source": [
        "# If training has performed, plot the\n",
        "if training == True:\n",
        "  plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSqVawayssAe"
      },
      "source": [
        "### Parameters saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nSuCAgZssAe"
      },
      "outputs": [],
      "source": [
        "if save == True:\n",
        "   save_params(model, local_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "418PaircsZ6S"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR7YFMAtzQo9"
      },
      "source": [
        "## Averages Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM57wPMYyzYB"
      },
      "outputs": [],
      "source": [
        "avgs = []\n",
        "val_masks = []\n",
        "\n",
        "for val_idx in val_idxs:\n",
        "\n",
        "  print(f\"Prediction idx {val_idx}\")\n",
        "  print(\"-----\")\n",
        "\n",
        "  if val_compute == True:\n",
        "\n",
        "    val_image = cv2.imread(str(images_paths[val_idx]))\n",
        "    avg = predict(model, device, val_image)\n",
        "\n",
        "  else:\n",
        "\n",
        "    avg = get_pred(model, local_path, project_path, val_idx)\n",
        "\n",
        "  raw_output = beautify_output(avg)\n",
        "\n",
        "  avgs.append(avg)\n",
        "\n",
        "  val_mask = cv2.imread(str(masks_paths[val_idx]))\n",
        "  val_masks.append(val_mask)\n",
        "\n",
        "  # averages saving\n",
        "  if val_avg_write == True:\n",
        "    save_pred(raw_output, val_idx)\n",
        "\n",
        "  print(\"=================\")\n",
        "\n",
        "print(\"Done fetching the predictions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpEQk973zzKt"
      },
      "source": [
        "## Averages Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnIj2H7uzzKt"
      },
      "outputs": [],
      "source": [
        "thr = 0.5 # threshold\n",
        "thr_avgs = []\n",
        "\n",
        "for avg in avgs:\n",
        "\n",
        "  thr_avg = threshold_output(avg, thr)\n",
        "  thr_avgs.append(thr_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVtmZli8TZ8w"
      },
      "outputs": [],
      "source": [
        "thr_avgs_to_output = []\n",
        "\n",
        "for thr_avg in thr_avgs:\n",
        "  thr_avgs_to_output.append(beautify_output(thr_avg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlTkjvj10NPl"
      },
      "source": [
        "## Prediction Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBMt4W50Q8Cl"
      },
      "outputs": [],
      "source": [
        "format_images_grid(thr_avgs_to_output, val_idxs)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxP5lc_k0XQO"
      },
      "source": [
        "### Prediction Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YntMSJKlcVx"
      },
      "outputs": [],
      "source": [
        "if val_output_write == True:\n",
        "\n",
        "  for i, val_idx in enumerate(val_idxs):\n",
        "    output = thr_avgs_to_output[i]\n",
        "    save_thr_pred(output, val_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwq80M1UzzKt"
      },
      "source": [
        "## Mask-prediction Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2yy7ivuXqfm"
      },
      "outputs": [],
      "source": [
        "# Define colors for each case\n",
        "colors = ['black', 'green', 'red', 'white']\n",
        "color_labels = ['correct non tumor', 'false positive', 'false negative', 'correct tumor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmtPoDy4WTLb"
      },
      "outputs": [],
      "source": [
        "legend_handles = [plt.Rectangle((0,0),1,1, color=color) for color in colors]\n",
        "\n",
        "visualise_comparison_legend(legend_handles, color_labels)\n",
        "\n",
        "comp_images = get_comparison_images(thr_avgs, val_masks)\n",
        "format_images_grid(comp_images, val_idxs, cmap=plt.cm.colors.ListedColormap(colors), columns=2)\n",
        "\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUOaMgj_0keP"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgTfW7K30kel"
      },
      "outputs": [],
      "source": [
        "tumor = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlc6yKeS1mUX"
      },
      "source": [
        "### Metric Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHjC8RsSLhjp"
      },
      "outputs": [],
      "source": [
        "columns = ['Accuracy', 'Precision', 'Specificity', \"Sensibility\", \"IoU\",\n",
        "           \"Dice coeff.\", \"F1 score\"]\n",
        "\n",
        "# Create an empty DataFrame with defined columns\n",
        "df = pd.DataFrame(columns=columns)\n",
        "\n",
        "conf_matrices = []\n",
        "conf_norm_matrices = []\n",
        "\n",
        "for count, idx in enumerate(val_idxs):\n",
        "\n",
        "  val_mask = val_masks[count]\n",
        "  thr_avg = thr_avgs[count]\n",
        "\n",
        "  y_true = get_true_labels(val_mask, tumor)\n",
        "  y_pred = get_pred_labels(thr_avg, tumor)\n",
        "\n",
        "  conf_matrices.append(conf_matrix(y_true, y_pred))\n",
        "  conf_norm_matrices.append(conf_matrix(y_true, y_pred, normalise=\"true\"))\n",
        "\n",
        "  metrics_row_df = get_metrics_row_df(y_true, y_pred)\n",
        "\n",
        "  df = pd.concat([df, metrics_row_df], ignore_index=True)\n",
        "\n",
        "# Assign custom index labels to the DataFrame\n",
        "df.index = val_idxs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBT4XBkN1Mxt"
      },
      "source": [
        "### Metrics Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIc4uzUj8koV"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyxtuvlZ1QX3"
      },
      "source": [
        "### Average Metrics Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me2ir_lrPS9T"
      },
      "outputs": [],
      "source": [
        "df.mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOATMTP_0keo"
      },
      "source": [
        "### Confusion Matrix Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Na_riKcQ0keq"
      },
      "outputs": [],
      "source": [
        "for i in range(len(conf_matrices)):\n",
        "  fig = format_conf_matrices(val_idxs[i], conf_matrices[i], conf_norm_matrices[i])\n",
        "  if val_conf_matr_write == True:\n",
        "    fig.savefig(f\"conf_matr_{val_idxs[i]}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs4yrm_7ssAe"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqUodwga1sEx"
      },
      "source": [
        "## Average Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B22NAB3DkVZc"
      },
      "outputs": [],
      "source": [
        "print(f\"Prediction idx {test_idx}\")\n",
        "print(\"-----\")\n",
        "\n",
        "if test_compute == True:\n",
        "\n",
        "  test_image = cv2.imread(str(images_paths[test_idx]))\n",
        "  avg = predict(model, device, test_image)\n",
        "\n",
        "else:\n",
        "\n",
        "  avg = get_pred(model, local_path, project_path, test_idx)\n",
        "\n",
        "raw_output = beautify_output(avg)\n",
        "\n",
        "test_mask = cv2.imread(str(masks_paths[test_idx]))\n",
        "\n",
        "print(\"=================\")\n",
        "\n",
        "print(\"Done fetching the prediction.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy8vGINk1bf-"
      },
      "source": [
        "### Average Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmfEKgbi1bBY"
      },
      "outputs": [],
      "source": [
        "if test_avg_write == True:\n",
        "  save_pred(raw_output, test_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTC0saSc1w0t"
      },
      "source": [
        "## Averages Thresholding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H68gdthmvX9"
      },
      "outputs": [],
      "source": [
        "thr_avg = threshold_output(avg, thr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPoGyVpt2EMt"
      },
      "source": [
        "## Prediction Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UatZOwbio8Hw"
      },
      "outputs": [],
      "source": [
        "thr_avg_to_output = beautify_output(thr_avg)\n",
        "\n",
        "format_images_grid([thr_avg_to_output], [test_idx])\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx2ZmWQY2KLk"
      },
      "source": [
        "### Prediction Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgLVPkyQnPqh"
      },
      "outputs": [],
      "source": [
        "if test_output_write == True:\n",
        "  save_thr_pred(thr_avg_to_output, test_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-LL69NL2NUm"
      },
      "source": [
        "## Mask-prediction Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z359U4v4nbeb"
      },
      "outputs": [],
      "source": [
        "# Define colors for each case\n",
        "colors = ['black', 'green', 'red', 'white']\n",
        "color_labels = ['correct non tumor', 'false positive', 'false negative', 'correct tumor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQIkFPLrnjcs"
      },
      "outputs": [],
      "source": [
        "legend_handles = [plt.Rectangle((0,0),1,1, color=color) for color in colors]\n",
        "\n",
        "visualise_comparison_legend(legend_handles, color_labels)\n",
        "\n",
        "comp_images = get_comparison_images([thr_avg], [test_mask])\n",
        "\n",
        "format_images_grid(comp_images, [test_idx], cmap=plt.cm.colors.ListedColormap(colors), columns=1)\n",
        "\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHh-XaO-rs3q"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0KLLH5TrtfK"
      },
      "outputs": [],
      "source": [
        "tumor = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tg7Hk0V2Vjq"
      },
      "source": [
        "### Metric Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnF9VISSr2pH"
      },
      "outputs": [],
      "source": [
        "columns = ['Accuracy', 'Precision', 'Specificity', \"Sensibility\", \"IoU\",\n",
        "           \"Dice coeff.\", \"F1 score\"]\n",
        "\n",
        "# Create an empty DataFrame with defined columns\n",
        "df = pd.DataFrame(columns=columns)\n",
        "\n",
        "y_true = get_true_labels(test_mask, tumor)\n",
        "y_pred = get_pred_labels(thr_avg, tumor)\n",
        "\n",
        "conf_m = conf_matrix(y_true, y_pred)\n",
        "conf_norm_m = conf_matrix(y_true, y_pred, normalise=\"true\")\n",
        "\n",
        "metrics_row_df = get_metrics_row_df(y_true, y_pred)\n",
        "\n",
        "df = pd.concat([df, metrics_row_df], ignore_index=True)\n",
        "\n",
        "# Assign custom index labels to the DataFrame\n",
        "df.index = [test_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYdoDY7u2hk1"
      },
      "source": [
        "### Metrics Visualisaiton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WORXuFUQsKE5"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRARFmvo2vaB"
      },
      "source": [
        "### Confusion Matrix Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anvJsJWhsb5F"
      },
      "outputs": [],
      "source": [
        "fig = format_conf_matrices(test_idx, conf_m, conf_norm_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIf-rt8ysnb6"
      },
      "outputs": [],
      "source": [
        "if val_conf_matr_write == True:\n",
        "    fig.savefig(f\"conf_matr_{test_idx}.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2M5uynwjvhrA",
        "rNSBjD1SvhrH",
        "PF3GTE8GvhrH",
        "zNPD1m41vhrI",
        "IrEGsF4CvhrJ",
        "bs4yrm_7ssAe"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
