{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M5uynwjvhrA"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3iq2bzpvhrG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tabulate import tabulate\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage.segmentation import find_boundaries\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Torch libraries\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision.transforms import transforms\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNSBjD1SvhrH"
      },
      "source": [
        "## Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il4XeK0qvhrH"
      },
      "outputs": [],
      "source": [
        "seed_value = 42\n",
        "\n",
        "np.random.seed(seed_value)  # NumPy\n",
        "torch.manual_seed(seed_value)  # PyTorch CPU\n",
        "torch.cuda.manual_seed_all(seed_value)  # PyTorch GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF3GTE8GvhrH"
      },
      "source": [
        "# Data Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnZngh4G97il"
      },
      "outputs": [],
      "source": [
        "def equalise_image(image):\n",
        "   gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "   equalized_image = cv2.equalizeHist(gray_image)\n",
        "   equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "   return equalized_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJtHvioHxnP5"
      },
      "source": [
        "Defines a custom dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8OX-sjzxlq3"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "   def __init__(self, images, labels, transform=None):\n",
        "      self.images = images\n",
        "      self.labels = labels\n",
        "      self.transform = transform\n",
        "\n",
        "   def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "   def __getitem__(self, idx):\n",
        "      image = self.images[idx]\n",
        "      imageResize = cv2.resize(image, (299, 299))\n",
        "\n",
        "      label = self.labels[idx]\n",
        "      if self.transform:\n",
        "         imageResize = self.transform(imageResize)\n",
        "      return imageResize, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESvUUDDe97im"
      },
      "source": [
        "We also have the choice to equalise the images (unfortunately only in black and white)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGxg8swexrTR"
      },
      "outputs": [],
      "source": [
        "def load_images_with_masks(image_directory, mask_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_filename in os.listdir(image_directory):\n",
        "        if image_filename.endswith(\".tif\"):\n",
        "            image_filepath = os.path.join(image_directory, image_filename)\n",
        "            mask_filename = image_filename + '.png'\n",
        "            mask_filepath = os.path.join(mask_directory, mask_filename)\n",
        "            try:\n",
        "                image = cv2.imread(image_filepath)\n",
        "\t\t\t\t        #Â image = equalise_image(image)\n",
        "                mask = cv2.imread(mask_filepath, cv2.IMREAD_GRAYSCALE)\n",
        "                images.append(image)\n",
        "                labels.append(mask)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {image_filename} or mask: {e}\")\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGo-igvExt7w"
      },
      "outputs": [],
      "source": [
        "def extract_subimages(images, labels, removeIndex, subimage_size=64, step_size=8):\n",
        "    subimages = []\n",
        "    sublabels = []\n",
        "    for i in range(len(images)):\n",
        "        if i != removeIndex: #skip the image used for testing\n",
        "            image = images[i]\n",
        "            label = labels[i]\n",
        "            height, width = image.shape[:2]\n",
        "            for y in range(0, height - subimage_size + 1, step_size):\n",
        "                for x in range(0, width - subimage_size + 1, step_size):\n",
        "                    subimage = image[y:y+subimage_size, x:x+subimage_size]\n",
        "                    sublabel = label[y:y+subimage_size, x:x+subimage_size]\n",
        "                    if np.all(sublabel == 0) or np.all(sublabel == 255):\n",
        "                        subimages.append(subimage)\n",
        "                        sublabels.append(sublabel[0][0])  # Assuming all values are the same in the sublabel\n",
        "    return np.array(subimages), np.array(sublabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApkBTSvsgGur"
      },
      "outputs": [],
      "source": [
        "def load_data(k=100):\n",
        "\n",
        "  image_directory = \"neuroendocrine_/images\"\n",
        "  mask_directory = \"neuroendocrine_/masks\"\n",
        "\n",
        "  images, labels = load_images_with_masks(image_directory, mask_directory)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3UHWDQzjrL8"
      },
      "outputs": [],
      "source": [
        "def load_train_data(images, labels):\n",
        "\n",
        "  train_images, train_labels = extract_subimages(images[:-1], labels, 29)\n",
        "  del images\n",
        "\n",
        "  # labels should be 0 or 1\n",
        "  train_labels[train_labels == 255] = 1\n",
        "\n",
        "  print(\"Shape of the full train_images array:\", train_images.shape)\n",
        "  print(\"Shape of the full train_labels array:\", train_labels.shape)\n",
        "\n",
        "  return train_images, train_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo9KSSYfkksu"
      },
      "outputs": [],
      "source": [
        "def load_val_data(images, labels, k=100):\n",
        "\n",
        "  val_images, val_labels = extract_subimages(images[-1:], labels, -1)\n",
        "  del labels\n",
        "\n",
        "  val_images = val_images[:k]\n",
        "  val_labels = val_labels[:k]\n",
        "\n",
        "  # labels should be 0 or 1\n",
        "  val_labels[val_labels == 255] = 1\n",
        "\n",
        "  print(\"Shape of the val_labels array:\", val_images.shape)\n",
        "  print(\"Shape of the val_labels array:\", val_labels.shape)\n",
        "\n",
        "  return val_images, val_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaGEgI_Ij_k6"
      },
      "outputs": [],
      "source": [
        "def get_indices(labels):\n",
        "\n",
        "  # Assuming train_images and train_labels are your training data\n",
        "  # Calculate the indices of each class\n",
        "  class_0_idxs = np.where(labels == 0)[0]\n",
        "  class_1_idxs = np.where(labels == 1)[0]\n",
        "\n",
        "  print(f\"{len(class_0_idxs)} non-tumor images\")\n",
        "  print(f\"{len(class_1_idxs)} tumor images\")\n",
        "\n",
        "  return class_0_idxs, class_1_idxs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_transforms(augment=False):\n",
        "\n",
        "  if augment == True:\n",
        "    transform = transforms.Compose([\n",
        "      transforms.ToPILImage(),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "      ])\n",
        "  else:\n",
        "    transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "      ])\n",
        "\n",
        "  return transform\n"
      ],
      "metadata": {
        "id": "jLZd0Wp4MRPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEJgMeR9g5EW"
      },
      "outputs": [],
      "source": [
        "def create_full_dataloader(batch_size=100, k=100, augment=False):\n",
        "\n",
        "  images, labels = load_data(k=k)\n",
        "\n",
        "  train_images, train_labels = load_train_data(images, labels)\n",
        "  val_images, val_labels = load_val_data(images, labels, k)\n",
        "\n",
        "  del images, labels\n",
        "\n",
        "  transform = setup_transforms(augment)\n",
        "\n",
        "  # Create the undersampled dataset\n",
        "  train_dataset = CustomDataset(train_images, train_labels, transform=transform)\n",
        "  val_dataset = CustomDataset(val_images, val_labels, transform=transform)\n",
        "\n",
        "  del train_images\n",
        "  del train_labels\n",
        "\n",
        "  # Create the data loader for the undersampled dataset\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  del train_dataset\n",
        "\n",
        "  return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnHfORL3hnvr"
      },
      "outputs": [],
      "source": [
        "def create_balanced_dataloader(batch_size=100, k=100, augment=False):\n",
        "\n",
        "  images, labels = load_data(k=k)\n",
        "\n",
        "  train_images, train_labels = load_train_data(images, labels)\n",
        "  val_images, val_labels = load_val_data(images, labels, k)\n",
        "\n",
        "  del images, labels\n",
        "\n",
        "  class_0_idxs, class_1_idxs = get_indices(train_labels)\n",
        "\n",
        "  # Determine the size of the minority class\n",
        "  minority_class_size = len(class_0_idxs)\n",
        "\n",
        "  sel_class_0_idxs = class_0_idxs\n",
        "  # Randomly sample the same number of samples from the majority class\n",
        "  sel_class_1_idxs = np.random.choice(class_1_idxs, minority_class_size, replace=False)\n",
        "\n",
        "  sel_idxs = np.concatenate([sel_class_0_idxs, sel_class_1_idxs])\n",
        "\n",
        "  del class_0_idxs, class_1_idxs\n",
        "\n",
        "  # Shuffle the indices to mix the samples from both classes\n",
        "  np.random.shuffle(sel_idxs)\n",
        "\n",
        "  # Use the undersampled indices to create a new balanced dataset\n",
        "  train_images = train_images[sel_idxs]\n",
        "  train_labels = train_labels[sel_idxs]\n",
        "\n",
        "  del sel_idxs\n",
        "\n",
        "  print(\"Shape of the selected train_images array:\", train_images.shape)\n",
        "  print(\"Shape of the selected train_labels array:\", train_labels.shape)\n",
        "\n",
        "  transform = setup_transforms(augment)\n",
        "\n",
        "  # Create the undersampled dataset\n",
        "  train_dataset = CustomDataset(train_images, train_labels, transform=transform)\n",
        "  val_dataset = CustomDataset(val_images, val_labels, transform=transform)\n",
        "\n",
        "  del train_images\n",
        "  del train_labels\n",
        "\n",
        "  # Create the data loader for the undersampled dataset\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  del train_dataset\n",
        "\n",
        "  return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBRBonz_iAeN"
      },
      "outputs": [],
      "source": [
        "def create_custom_dataloader(batch_size=100, n=60000, k=100, augment=False):\n",
        "\n",
        "  images, labels = load_data(k=k)\n",
        "\n",
        "  train_images, train_labels = load_train_data(images, labels)\n",
        "  val_images, val_labels = load_val_data(images, labels, k)\n",
        "\n",
        "  del images, labels\n",
        "\n",
        "  class_0_idxs, class_1_idxs = get_indices(train_labels)\n",
        "  num_idxs = len(train_labels)\n",
        "  num_0_idxs = len(class_0_idxs)\n",
        "  num_1_idxs = len(class_1_idxs)\n",
        "  # Define weights for each sample\n",
        "  sample_weights = np.where(train_labels==0, num_idxs/num_0_idxs, num_idxs/num_1_idxs)\n",
        "\n",
        "  # Create a WeightedRandomSampler\n",
        "  sampler = WeightedRandomSampler(weights=sample_weights, num_samples=n, replacement=True)\n",
        "\n",
        "  transform = setup_transforms()\n",
        "\n",
        "  # Create the undersampled dataset\n",
        "  train_dataset = CustomDataset(train_images, train_labels, transform=transform)\n",
        "  val_dataset = CustomDataset(val_images, val_labels, transform=transform)\n",
        "\n",
        "  del train_images\n",
        "  del train_labels\n",
        "\n",
        "  # Create the data loader for the undersampled dataset\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  # TODO add final dataloader size\n",
        "\n",
        "  del train_dataset\n",
        "\n",
        "  return train_loader, val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmOA8GJZyfmY"
      },
      "outputs": [],
      "source": [
        "def get_images(dataset_path, test=False):\n",
        "\n",
        "   suff = None\n",
        "\n",
        "   if test == False:\n",
        "      suff = \"images\"\n",
        "   else:\n",
        "      suff = \"masks\"\n",
        "\n",
        "   images_dir_path = Path(f\"{dataset_path}/{suff}\")\n",
        "\n",
        "   # List all files in the folder\n",
        "   images_paths = sorted(list(images_dir_path.iterdir()))\n",
        "\n",
        "   return images_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNPD1m41vhrI"
      },
      "source": [
        "# Models Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxtbCQ2Pyrkh"
      },
      "outputs": [],
      "source": [
        "def import_model(model_name):\n",
        "  if model_name == \"inceptionv3\":\n",
        "    # Load InceptionV3 model pretrained on ImageNet\n",
        "    model = models.inception_v3(weights='DEFAULT')\n",
        "  elif model_name == \"AlexNet\":\n",
        "    # Load AlexNet model pretrained on ImageNet\n",
        "    model = models.alexnet(weights='DEFAULT')\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTEotK27ytTu"
      },
      "outputs": [],
      "source": [
        "def setup_model(model, device):\n",
        "  # Set the model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  num_classes = 2  # Assuming CustomDataset has a 'classes' attribute\n",
        "\n",
        "  if isinstance(model, models.inception.Inception3):\n",
        "    # Freeze all the parameters\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    # Modify the last layer to fit your number of classes\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(model.fc.in_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "  elif isinstance(model, models.AlexNet):\n",
        "    model.classifier.add_module('7', nn.ReLU())\n",
        "    model.classifier.add_module('8', nn.Linear(1000, 512))\n",
        "    model.classifier.add_module('9', nn.ReLU())\n",
        "    model.classifier.add_module('10', nn.Linear(512, 128))\n",
        "    model.classifier.add_module('11', nn.ReLU())\n",
        "    model.classifier.add_module('12', nn.Linear(128, 32))\n",
        "    model.classifier.add_module('13', nn.ReLU())\n",
        "    model.classifier.add_module('14', nn.Linear(32, 2))\n",
        "\n",
        "  # Move the model to the GPU\n",
        "  model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz3sEPY3zK4a"
      },
      "outputs": [],
      "source": [
        "def setup_training(model):\n",
        "\n",
        "\tif isinstance(model, models.inception.Inception3):\n",
        "\t\tmodel.fc.train()\n",
        "\n",
        "\telif isinstance(model, models.AlexNet):\n",
        "\t\tmodel.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n95YhXF1zNo_"
      },
      "outputs": [],
      "source": [
        "def validate(model, criterion, dataloader, device):\n",
        "\n",
        "  val_loss = 0.0\n",
        "  correct_predictions = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  for inputs, labels in dataloader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    val_loss += loss.item() * inputs.size(0)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct_predictions += (predicted == labels).sum().item()\n",
        "    total_samples += labels.size(0)\n",
        "\n",
        "  val_loss /= total_samples\n",
        "  accuracy = correct_predictions / total_samples\n",
        "\n",
        "  print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkl7q5tUzvXU"
      },
      "source": [
        "###Â Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-UJCwwNy0Zn"
      },
      "outputs": [],
      "source": [
        "def training_loop(model, optimizer, loss_fn, train_dataloader, val_dataloader, device,\n",
        "                  num_epochs, max_train, print_every, losses):\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader, 1):\n",
        "\n",
        "      # Fetch inputs and labels\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # Initialise gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Feedforward\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss = loss_fn(outputs, labels)\n",
        "      loss.backward()\n",
        "\n",
        "      # Update parameters\n",
        "      optimizer.step()\n",
        "\n",
        "      # Append loss\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      # Print average loss every print_every iterations\n",
        "      if i % print_every == 0:\n",
        "        epoch_loss = running_loss / (print_every * len(inputs))\n",
        "        losses.append(epoch_loss)\n",
        "        print(f\"Iteration [{i}/{len(train_dataloader)}], Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "        running_loss = 0.0\n",
        "        validate(model, loss_fn, val_dataloader, device)\n",
        "        print(\"------------------\")\n",
        "\n",
        "      # Iteration limit\n",
        "      if i >= max_train:\n",
        "        break\n",
        "\n",
        "    print(\"==========================\")\n",
        "\n",
        "  return losses\n",
        "\n",
        "# TODO move inside train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSVZnIKLzGMb"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loss_fn, dataloader, val_dataloader, device,\n",
        "          num_epochs=1, max_train=200, print_every=10, losses=[]):\n",
        "\n",
        "  setup_training(model)\n",
        "\n",
        "  training_loop(model, optimizer, loss_fn, dataloader, val_dataloader, device, num_epochs, max_train, print_every, losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tXu3CQt0ZwC"
      },
      "outputs": [],
      "source": [
        "def load_params(model, local_path, project_path, device):\n",
        "\n",
        "  model_path = None\n",
        "  params_path = None\n",
        "\n",
        "  if isinstance(model, models.inception.Inception3):\n",
        "\n",
        "    model_path = \"inception_v3\"\n",
        "    params_path = \"incv3_params.pth\"\n",
        "\n",
        "  elif isinstance(model, models.AlexNet):\n",
        "\n",
        "    model_path = \"AlexNet\"\n",
        "    params_path = \"AlexNet_params.pth\"\n",
        "\n",
        "  full_path = f\"{local_path}/{params_path}\"\n",
        "\n",
        "  # Load the saved dictionary into your model\n",
        "\n",
        "  try:\n",
        "    state_dict = torch.load(full_path, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "  except:\n",
        "    print(\"WARNING: default ImageNet weights have been loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eflxc2RO0cRf"
      },
      "outputs": [],
      "source": [
        "def save_params(model, local_path):\n",
        "\n",
        "  params_path = None\n",
        "\n",
        "  if isinstance(model, models.inception.Inception3):\n",
        "    params_path = \"incv3_params.pth\"\n",
        "\n",
        "  elif isinstance(model, models.AlexNet):\n",
        "    params_path = \"AlexNet_params.pth\"\n",
        "\n",
        "  #Â Save the model state\n",
        "  torch.save(model.state_dict(), f\"{local_path}/{params_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtkmEDPa0p6J"
      },
      "outputs": [],
      "source": [
        "def predict(model, device, image):\n",
        "\n",
        "  testImage = image\n",
        "\n",
        "  subimage_size = 64\n",
        "  step_size = 8\n",
        "\n",
        "  height, width = testImage.shape[:2]\n",
        "  outputHeight = height - height % step_size\n",
        "  outputWidth = width - width % step_size\n",
        "  tumorCount = np.zeros((outputHeight, outputWidth))\n",
        "  count = np.zeros((outputHeight, outputWidth))\n",
        "\n",
        "  # Move model to GPU\n",
        "  model.eval()\n",
        "\n",
        "  for row in range(0, height - subimage_size + 1, step_size):\n",
        "    if row % 50 == 0:\n",
        "      print('Row ' + str(row) + '/ ' + str(height))\n",
        "    for col in range(0, width - subimage_size + 1, step_size):\n",
        "      subimage = testImage[row:row+subimage_size, col:col+subimage_size]\n",
        "\n",
        "      # Prepare subimage for InceptionV3\n",
        "      # Resize the subimage using OpenCV\n",
        "      resized_subimage = cv2.resize(subimage, (299, 299))\n",
        "\n",
        "      # Define the transformations\n",
        "      transform = transforms.Compose([\n",
        "          transforms.ToTensor(),  # Convert image to tensor\n",
        "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
        "          ])\n",
        "\n",
        "      # Apply the transformations and move to GPU\n",
        "      transformed_subimage = transform(resized_subimage).to(device)\n",
        "\n",
        "      # Compute output on GPU\n",
        "      with torch.no_grad():\n",
        "        output = model(transformed_subimage.unsqueeze(0))\n",
        "        label = torch.argmax(output)\n",
        "\n",
        "      # Write to matrix\n",
        "      if label == 1:\n",
        "        tumorCount[row:row+subimage_size, col:col+subimage_size] += 1\n",
        "      count[row:row+subimage_size, col:col+subimage_size] += 1\n",
        "\n",
        "  # Calculate average tumor occurrence per submatrix\n",
        "  avg = np.divide(tumorCount, count)\n",
        "\n",
        "  return avg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Loss Functions"
      ],
      "metadata": {
        "id": "Ol4Niv3jxzRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss(alpha, gamma):\n",
        "\n",
        "  def _focal_loss(outputs, labels):\n",
        "\n",
        "    # Convert labels to int64 type\n",
        "    labels = labels.long()\n",
        "\n",
        "    # Compute class weights based on the frequency of each class in the labels\n",
        "    class_counts = torch.bincount(labels)\n",
        "\n",
        "    class_weights = (1 / class_counts.float()).clone().detach()\n",
        "\n",
        "    # Normalize the class weights\n",
        "    class_weights /= class_weights.sum()\n",
        "\n",
        "    # Compute softmax along the class dimension\n",
        "    input_softmax = F.softmax(outputs, dim=1)\n",
        "    # Gather the probabilities of the true class\n",
        "    p_t = torch.gather(input_softmax, 1, labels.view(-1, 1))\n",
        "    # Compute binary cross entropy loss\n",
        "    bce_loss = F.cross_entropy(outputs, labels, reduction='none')\n",
        "    # Compute focal loss\n",
        "    focal_loss = alpha * (1 - p_t) ** gamma * bce_loss\n",
        "    return torch.mean(focal_loss)\n",
        "\n",
        "  return _focal_loss"
      ],
      "metadata": {
        "id": "A9_Q8W-Cx1-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrEGsF4CvhrJ"
      },
      "source": [
        "# Evaluation Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIowM7w60sbW"
      },
      "outputs": [],
      "source": [
        "def get_pred(model, local_path, project_path, img_idx):\n",
        "\n",
        "  if isinstance(model, models.inception.Inception3):\n",
        "    model_name = \"inception_v3\"\n",
        "\n",
        "  elif isinstance(model, models.AlexNet):\n",
        "    model_name = \"AlexNet\"\n",
        "\n",
        "  if os.path.exists(f\"avg_{img_idx}.png\"):\n",
        "    avg_path = f\"{local_path}/avg_{img_idx}.png\"\n",
        "    print(\"avg image found in the runtime.\")\n",
        "  else:\n",
        "    print(\"No selected avg image. Loading not succeeded!\")\n",
        "    return None\n",
        "\n",
        "  avg = cv2.imread(avg_path)\n",
        "\n",
        "  # Convert the image to grayscale\n",
        "  avg = cv2.cvtColor(avg, cv2.COLOR_BGR2GRAY)\n",
        "  avg = avg/255\n",
        "\n",
        "  return avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuChMsac0tr1"
      },
      "outputs": [],
      "source": [
        "def beautify_output(avg):\n",
        "  printAvg = avg*255\n",
        "  return printAvg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgxzeKvX0vah"
      },
      "outputs": [],
      "source": [
        "def threshold_output(avg, thr=0.5):\n",
        "  modelGuess = np.where(avg >= thr, 255, 0).astype(np.uint8)[:1283, :2040]\n",
        "  return modelGuess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SujDwKgD0yBq"
      },
      "outputs": [],
      "source": [
        "def visualise_output(printable):\n",
        "  # Displaying the numpy array as grayscale\n",
        "  plt.imshow(printable, cmap='gray', vmin=0, vmax=255)  # Specify vmin and vmax\n",
        "  plt.axis('off')  # Turn off axis\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_pred(avg, img_idx):\n",
        "  if avg is not None:\n",
        "    cv2.imwrite(f'avg_{img_idx}.png', avg)\n",
        "  else:\n",
        "    print(\"No avg has been provided. Saving not succeeded!\")"
      ],
      "metadata": {
        "id": "pd9c4RDXvSn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc180reCvhrJ"
      },
      "outputs": [],
      "source": [
        "def save_thr_pred(thr_pred, img_idx):\n",
        "  if thr_pred is not None:\n",
        "    cv2.imwrite(f'pred_image_{img_idx}.png', thr_pred)\n",
        "  else:\n",
        "    print(\"No thr_pred has been provided. Saving not succeeded!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualise_comparison(thr_output, testMask):\n",
        "\n",
        "\tcombined_matrix = 2 * thr_output/255 + testMask[:,:,0]/255\n",
        "\n",
        "\t# Define colors for each case\n",
        "\tcolors = ['black', 'green', 'red', 'white']\n",
        "\tcolor_labels = ['correct non tumor', 'false positive', 'false negative', 'correct tumor']\n",
        "\n",
        "\t# Plot the combined matrix\n",
        "\tplt.figure(figsize=(10, 8))\n",
        "\tplt.imshow(combined_matrix, cmap=plt.cm.colors.ListedColormap(colors))\n",
        "\n",
        "\t# Create a separate legend outside the plot\n",
        "\tlegend_handles = [plt.Rectangle((0,0),1,1, color=color) for color in colors]\n",
        "\tplt.legend(legend_handles, color_labels, loc='upper left', bbox_to_anchor=(1, 1), facecolor='dimgrey')\n",
        "\n",
        "\tplt.show()"
      ],
      "metadata": {
        "id": "-76yXBZayOqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LAK_Wrv1JZQ"
      },
      "outputs": [],
      "source": [
        "def pixel_accuracy(y_true, y_pred):\n",
        "\n",
        "  return accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "\n",
        "def pixel_precision(y_true, y_pred):\n",
        "\n",
        "  true_positives = np.sum(np.logical_and(y_true, y_pred))\n",
        "  false_positives = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
        "\n",
        "  if true_positives + false_positives == 0:\n",
        "    return 0.0\n",
        "  else:\n",
        "    return true_positives / (true_positives + false_positives)\n",
        "\n",
        "def pixel_sensitivity(y_true, y_pred): # Also known as RECALL\n",
        "\n",
        "  true_positives = np.sum(np.logical_and(y_true, y_pred))\n",
        "  false_negatives = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
        "\n",
        "  if true_positives + false_negatives == 0:\n",
        "    return 0.0\n",
        "  else:\n",
        "    return true_positives / (true_positives + false_negatives)\n",
        "\n",
        "def pixel_specificity(y_true, y_pred):\n",
        "\ttrue_negatives = np.sum(np.logical_and(np.logical_not(y_true), np.logical_not(y_pred)))\n",
        "\tfalse_positives = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
        "\n",
        "\tif true_negatives + false_positives == 0:\n",
        "\t\treturn 0.0\n",
        "\telse:\n",
        "\t\treturn true_negatives / (true_negatives + false_positives)\n",
        "\n",
        "\n",
        "def intersection_over_union(y_true, y_pred):\n",
        "\n",
        "  intersection = np.logical_and(y_true, y_pred)\n",
        "  union = np.logical_or(y_true, y_pred)\n",
        "  return np.sum(intersection) / np.sum(union)\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "\n",
        "  intersection = np.logical_and(y_true, y_pred)\n",
        "\n",
        "  return 2.0 * np.sum(intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "\tprecision = pixel_precision(y_true, y_pred)\n",
        "\trecall = pixel_specificity(y_true, y_pred)\n",
        "\n",
        "\tif precision + recall == 0:\n",
        "\t\treturn 0.0\n",
        "\telse:\n",
        "\t\treturn 2.0 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def boundary_f1_score(y_true, y_pred):\n",
        "\t# Find boundaries of the ground truth and predicted segmentation masks\n",
        "\ttrue_boundaries = find_boundaries(y_true)\n",
        "\tpred_boundaries = find_boundaries(y_pred)\n",
        "\n",
        "\t# Flatten the boundary masks\n",
        "\ttrue_boundaries_flat = true_boundaries.flatten()\n",
        "\tpred_boundaries_flat = pred_boundaries.flatten()\n",
        "\n",
        "\t# Compute F1 score for boundary detection\n",
        "\tf1_boundary = f1_score(true_boundaries_flat, pred_boundaries_flat)\n",
        "\n",
        "\treturn f1_boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9vBqrED1LEA"
      },
      "outputs": [],
      "source": [
        "def get_true_labels(mask, tumor=True):\n",
        "  y_true = (mask[:,:,0]/255).astype(bool)\n",
        "\n",
        "  if tumor == False:\n",
        "    y_true = np.logical_not(y_true)\n",
        "\n",
        "  return y_true\n",
        "\n",
        "def get_pred_labels(mask, tumor=True):\n",
        "  y_pred = (mask/255).astype(bool)\n",
        "\n",
        "  if tumor == False:\n",
        "    y_pred = np.logical_not(y_pred)\n",
        "\n",
        "  return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RgomJz41MwV"
      },
      "outputs": [],
      "source": [
        "def show_metrics(acc, prec, spec, sens, iou, dice, f1_sc, bound_f1_sc):\n",
        "\n",
        "  # Organize the metrics into a list of lists\n",
        "  metrics_table = [\n",
        "    [\"Pixel Accuracy\", f\"{acc:0.4f}\"],\n",
        "    [\"Pixel Precision\", f\"{prec:0.4f}\"],\n",
        "    [\"Pixel Specificity (Recall)\", f\"{spec:0.4f}\"],\n",
        "    [\"Pixel Sensitivity\", f\"{sens:0.4f}\"],\n",
        "    [\"IoU\", f\"{iou:0.4f}\"],\n",
        "    [\"Dice Coeff.\", f\"{dice:0.4f}\"],\n",
        "    [\"F1 Score.\", f\"{f1_sc:0.4f}\"],\n",
        "    [\"Boundary F1 Score.\", f\"{bound_f1_sc:0.4f}\"],\n",
        "  ]\n",
        "\n",
        "  # Display the metrics table\n",
        "  print(tabulate(metrics_table, headers=[\"Metric\", \"Value\"], tablefmt=\"grid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLGYgI7UvhrK"
      },
      "outputs": [],
      "source": [
        "def conf_matrix(y_true, y_pred, normalise=None):\n",
        "\n",
        "  conf_matrix = confusion_matrix(y_true.flatten(), y_pred.flatten(), normalize=normalise)\n",
        "  return conf_matrix\n",
        "\n",
        "def format_conf_matrices(conf_matrix, conf_norm_matrix):\n",
        "\n",
        "  fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(14, 8))\n",
        "\n",
        "  text = \"\"\"\n",
        "  - 0: non-tumor pixel\n",
        "  - 1: tumor pixel\n",
        "  \"\"\"\n",
        "\n",
        "  fig.text(0.5, 0.90, text, ha='center', fontsize=16, color='black')\n",
        "\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5, square=True, ax=axs[0])\n",
        "  axs[0].set_title(\"Confusion matrix\")\n",
        "  axs[0].set_xlabel(\"Predicted label\")\n",
        "  axs[0].set_ylabel(\"True label\")\n",
        "\n",
        "  sns.heatmap(conf_norm_matrix, annot=True, fmt=\".2%\", cmap=\"Blues\", linewidths=.5, square=True, ax=axs[1])\n",
        "  axs[1].set_title(\"Confusion normalised matrix\")\n",
        "  axs[1].set_xlabel(\"Predicted label\")\n",
        "  axs[1].set_ylabel(\"True label\")\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6nSB1t51PRB"
      },
      "outputs": [],
      "source": [
        "def visualize_bordered_mask(testImage, modelGuess, radius):\n",
        "  # Define the disk structuring element\n",
        "  radius = 2\n",
        "  disk_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "\n",
        "  # Apply erosion using the disk structuring element\n",
        "  eroded_mask = cv2.erode(modelGuess, disk_kernel)\n",
        "\n",
        "  tumorBorder = modelGuess - eroded_mask\n",
        "\n",
        "  map_rgb = cv2.cvtColor(tumorBorder, cv2.COLOR_GRAY2RGB)\n",
        "  alpha = 0.5  # Adjust the transparency of the overlaid image\n",
        "  overlay = cv2.addWeighted(testImage[:1283, :2040], alpha, map_rgb, 1 - alpha, 0)\n",
        "\n",
        "  plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1ehzDrizBPY"
      },
      "source": [
        "# Notebook Control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8coyziazUbu"
      },
      "source": [
        "##Â Training/Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7KeJGMszMVi"
      },
      "source": [
        "Control the training/loading and saving functionalities:\n",
        "\n",
        "- **training**: if yes, performs the computational training of the model. Otherwise, downloads and loads the already trained parameters.\n",
        "- **save**: if yes, saves the current state of the model (regardless of the fact that the training has been performed or not).\n",
        "\n",
        "**Important**: write operations are performed even if files are already present in the runtime. Hence, old files are over-written."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0TPK9TlzTJF"
      },
      "outputs": [],
      "source": [
        "training = False\n",
        "save = False # regardless of the actual training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6k4mzTUzX8M"
      },
      "source": [
        "##Â Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BergBWW0zeI2"
      },
      "source": [
        "Control the prediction/loading and writing functionalities:\n",
        "\n",
        "- **pred**: if yes, performs the computational prediction of a selected image's segmentation. Otherwise, loads the file avg.png from the Colab runtime (if it is not present, it downloads it from th GitHub project's repo).\n",
        "- **avg_write**: if yes, write to the Colab runtime the raw output of the model based on the chosen image (regardless of the fact that the computation has been performed or not).\n",
        "- **output_write**: if yes, write to the Colab runtime the thresholded output of the model based on the chosen image (regardless of the fact that the computation has been performed or not).\n",
        "\n",
        "**Important**: write operations are performed even if files are already present in the runtime. Hence, old files are over-written."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV1LNtX7zlKT"
      },
      "outputs": [],
      "source": [
        "compute = False # If true, compute the mask prediction of a chosen image; otherwise, consider the already pre-computed prediction.\n",
        "avg_write = compute = False # If true, compute the mask prediction of a chosen image; otherwise, consider the already pre-computed prediction.\n",
        "conf_matr_write = False # Write the confusion matrices figure to Colab.\n",
        "output_write = False # Write the final output photo to Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjWNbPk0zpIi"
      },
      "outputs": [],
      "source": [
        "img_idx = 29 # index of image chosen for evaluation (loaded avg.png refers to 29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTrFF0S_ssAY"
      },
      "source": [
        "# Resources Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x61WbR9tssAZ"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Luca-Olivieri/NAML_project.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfp6Sv5TssAa"
      },
      "source": [
        "### Resources paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixBHnuqissAW"
      },
      "outputs": [],
      "source": [
        "local_path = \"/content/\"\n",
        "project_path = local_path+\"NAML_project\"\n",
        "dataset_path = local_path+\"neuroendocrine_\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0NaXTwvssAb"
      },
      "source": [
        "# Model Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1fezVKNssAb"
      },
      "source": [
        "Import one of the pre-trained models.\n",
        "\n",
        "Available models:\n",
        "\n",
        "- Inception v3\n",
        "- AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcWGs8jjssAb"
      },
      "outputs": [],
      "source": [
        "# model_name = \"inceptionv3\"\n",
        "model_name = \"AlexNet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ_N3B_JssAb"
      },
      "source": [
        "Select version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyKylxe-ssAc"
      },
      "outputs": [],
      "source": [
        "model = import_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XoKJaYtJiL2"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBJ7oy1VuqQM"
      },
      "outputs": [],
      "source": [
        "setup_model(model, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5eOBHuZssAc"
      },
      "source": [
        "# Data Ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbuA17mWssAc"
      },
      "source": [
        "Download dataset from GitHub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljz2R5XZssAc"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cialab/neuroendocrine_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVn-m3lZssAd"
      },
      "source": [
        "# Training/Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzxzqjLHssAd"
      },
      "source": [
        "Dataset is very unbalanced, so I create a dataset containing 50% tumor and 50% non tumor subimages.\n",
        "I tried to trained on the original unbaiased dataset and the network pretty much always predicted tumor (because in training 90% of subimages are tumor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXlCRTPq73vj"
      },
      "outputs": [],
      "source": [
        "train_loader = None\n",
        "val_loader = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgKdeXHc774c"
      },
      "outputs": [],
      "source": [
        "if training == True:\n",
        "\n",
        "  batch_size = 100\n",
        "\n",
        "  del train_loader, val_loader\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  train_loader, val_loader = create_custom_dataloader(batch_size, n=200_000, k=100, augment=True)\n",
        "  #Â train_loader, val_loader = create_full_dataloader(batch_size, k=100, augment=True)\n",
        "  #Â train_loader, val_loader = create_balanced_dataloader(batch_size, k=100, augment=True)\n",
        "\n",
        "\t# n denotes the number of 64x64 images.\n",
        "\t# p denote the percentage of non-tumor images.\n",
        "  # k denotes the number of validation 64x64 images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKmjDX4q9dhd"
      },
      "outputs": [],
      "source": [
        "if training == True:\n",
        "\n",
        "\t# Define your optimiser:\n",
        "\toptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\t#Â optimizer = optim.Adam(model.parameters(), lr=0.00075)\n",
        "\t# optimizer = optim.AdamW(model.parameters(), lr=0.00075)\n",
        "\n",
        "\t# Define your loss function:\n",
        "\t#Â loss_fn = nn.CrossEntropyLoss()\n",
        "\tloss_fn = nn.CrossEntropyLoss(weight=torch.tensor([1.75, 1], dtype=torch.float).to(device))\n",
        "\t#Â loss_fn = focal_loss(alpha=0.4, gamma=1.5) # alpha = 1/(1+w_0)\n",
        "\n",
        "\tlosses = []\n",
        "\n",
        "\t# Proceed with the training loop\n",
        "\ttrain(model, optimizer, loss_fn, train_loader, val_loader, device,\n",
        "\t\t\t\t\t\t\t\tnum_epochs=2, max_train=1e8, print_every=10, losses=losses)\n",
        "else:\n",
        "\n",
        "\t# Load custom pre-trained parameters\n",
        "\tload_params(model, local_path, project_path, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIv3XxV5z7d7"
      },
      "outputs": [],
      "source": [
        "# If training has performed, plot the\n",
        "if training == True:\n",
        "  plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSqVawayssAe"
      },
      "source": [
        "### Parameters saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nSuCAgZssAe"
      },
      "outputs": [],
      "source": [
        "if save == True:\n",
        "   save_params(model, local_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs4yrm_7ssAe"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mb-UCl6NWb6"
      },
      "source": [
        "### Target visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOJk5uu5NfoA"
      },
      "source": [
        "Available photos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpV7IEN1MWQO"
      },
      "outputs": [],
      "source": [
        "images_paths = get_images(dataset_path, test=False)\n",
        "masks_paths = get_images(dataset_path, test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_oAqj56Nhvh"
      },
      "outputs": [],
      "source": [
        "# images_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV612ynFNLBA"
      },
      "source": [
        "Considered photo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMB3GZGtNKvk"
      },
      "outputs": [],
      "source": [
        "images_paths[img_idx], masks_paths[img_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gx4_O1eNQWv"
      },
      "outputs": [],
      "source": [
        "testImage = cv2.imread(str(images_paths[img_idx]))\n",
        "testMask = cv2.imread(str(masks_paths[img_idx]))\n",
        "\n",
        "plt.imshow(testImage)\n",
        "plt.imshow(testMask, alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBnlr7l_OCjM"
      },
      "source": [
        "### Mask prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB1jXuiEN94O"
      },
      "outputs": [],
      "source": [
        "if compute == True:\n",
        "  avg = predict(model, device, testImage)\n",
        "\n",
        "else:\n",
        "  avg = get_pred(\n",
        "    model, local_path, project_path, img_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8DI6qN6UvN4"
      },
      "source": [
        "### Mask predition saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igmPP8EDUuwe"
      },
      "outputs": [],
      "source": [
        "if avg_write == True:\n",
        "  save_pred(avg, img_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRUD68BFWs0O"
      },
      "source": [
        "### Visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud8k1pt4U7vd"
      },
      "source": [
        "Raw output of the segmentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHUv8YPXWV2H"
      },
      "outputs": [],
      "source": [
        "raw_output = beautify_output(avg)\n",
        "visualise_output(raw_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuKJkWeKW05p"
      },
      "source": [
        "Thresholded output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqiv-sieW5bw"
      },
      "outputs": [],
      "source": [
        "thr = 0.5 # threshold\n",
        "\n",
        "thr_output = threshold_output(avg, thr)\n",
        "visualise_output(thr_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation of the prediction quality:"
      ],
      "metadata": {
        "id": "aAtICM6OygkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualise_comparison(thr_output, testMask)"
      ],
      "metadata": {
        "id": "umYg2gjlyfAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxvope3SY_Fm"
      },
      "source": [
        "Prediction saving:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eAQYLTzY4rS"
      },
      "outputs": [],
      "source": [
        "if output_write == True:\n",
        "\tsave_thr_pred(thr_output, img_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOL0BtTBZkF1"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44kF0xCfcz_S"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz-UnoOD9q2S"
      },
      "outputs": [],
      "source": [
        "tumor = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNUWKlqHgNKB"
      },
      "outputs": [],
      "source": [
        "y_true = get_true_labels(testMask, tumor)\n",
        "y_pred = get_pred_labels(thr_output, tumor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "474st347c-A9"
      },
      "source": [
        "Compute metrics:\n",
        "- Accuracy\n",
        "- ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMmkox2-FlZk"
      },
      "outputs": [],
      "source": [
        "acc = pixel_accuracy(y_true, y_pred)\n",
        "prec = pixel_precision(y_true, y_pred)\n",
        "spec = pixel_specificity(y_true, y_pred)\n",
        "sens = pixel_sensitivity(y_true, y_pred)\n",
        "iou = intersection_over_union(y_true, y_pred)\n",
        "dice = dice_coefficient(y_true, y_pred)\n",
        "f1_sc = f1_score(y_true, y_pred)\n",
        "bound_f1_sc = f1_score(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdjuRowVGaQl"
      },
      "source": [
        "Show metric table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOMkvt4hcrBB"
      },
      "outputs": [],
      "source": [
        "show_metrics(acc, prec, spec, sens, iou, dice, f1_sc, bound_f1_sc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0INCXIvHjrf1"
      },
      "source": [
        "### Confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK8GopL95wMf"
      },
      "outputs": [],
      "source": [
        "type(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAUmBrVAjtW1"
      },
      "outputs": [],
      "source": [
        "conf_m = conf_matrix(y_true, y_pred)\n",
        "conf_norm_m = conf_matrix(y_true, y_pred, normalise=\"true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ueuAbgzm5k4"
      },
      "outputs": [],
      "source": [
        "fig = format_conf_matrices(conf_m, conf_norm_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgboCxRzuhS2"
      },
      "outputs": [],
      "source": [
        "if conf_matr_write == True:\n",
        "  fig.savefig(f\"conf_matr_{img_idx}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhcxQXe3HcGQ"
      },
      "source": [
        "### Visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDZSdwvrHeUX"
      },
      "source": [
        "Visualisation of prediction border onto input image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1MfJsT3IENA"
      },
      "outputs": [],
      "source": [
        "visualize_bordered_mask(testImage, thr_output, radius=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2M5uynwjvhrA",
        "rNSBjD1SvhrH",
        "PF3GTE8GvhrH",
        "zNPD1m41vhrI",
        "IrEGsF4CvhrJ"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}