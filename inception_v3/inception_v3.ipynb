{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T651Fez0gIA3"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw9CRMlwgIQa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E389v0xm1p1W"
      },
      "source": [
        "### Seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff2Z1-_srP2L"
      },
      "outputs": [],
      "source": [
        "# Sets seeds of all Python modules to a given value\n",
        "def set_seed(seed_value):\n",
        "    \"\"\"Set seed for reproducibility\"\"\"\n",
        "    np.random.seed(seed_value)  # NumPy\n",
        "    torch.manual_seed(seed_value)  # PyTorch CPU\n",
        "    torch.cuda.manual_seed_all(seed_value)  # PyTorch GPU\n",
        "\n",
        "# Set a seed value\n",
        "seed_value = 42\n",
        "set_seed(seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBFsIZO8bbSD"
      },
      "outputs": [],
      "source": [
        "local_path = \"/content/\"\n",
        "project_path = local_path+\"NAML_project/\"\n",
        "dataset_path = local_path+\"neuroendocrine_/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Kz5c-9bbSD"
      },
      "source": [
        "# Resources Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9WJhWpObbSD",
        "outputId": "22b39c11-f4c7-4b3d-ba2e-11617009215a"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Luca-Olivieri/NAML_project.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPNRpgN1f2Nx"
      },
      "source": [
        "# Model Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IzusWMB-ST8"
      },
      "source": [
        "Import pre-trained *Inception v3* model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJHj6Jp24_k2"
      },
      "outputs": [],
      "source": [
        "# Load InceptionV3 model pretrained on ImageNet\n",
        "inceptionv3 = models.inception_v3(weights='DEFAULT')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv3QjAfVEO90"
      },
      "outputs": [],
      "source": [
        "# Set the model to evaluation mode\n",
        "inceptionv3.eval()\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZaUnve8ESBr"
      },
      "source": [
        "Setup the model for **transfer learning**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYZJ13ZxyBtv"
      },
      "outputs": [],
      "source": [
        "# Freeze all the parameters except the last fully connected layer\n",
        "for param in inceptionv3.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the last layer to fit your number of classes\n",
        "num_classes = 2  # Assuming CustomDataset has a 'classes' attribute\n",
        "inceptionv3.fc = nn.Linear(inceptionv3.fc.in_features, num_classes)\n",
        "\n",
        "# Move the model to the GPU\n",
        "inceptionv3 = inceptionv3.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXMi_mh85Ps-"
      },
      "outputs": [],
      "source": [
        "model_version = \"v2\" # Select our model state version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dofqzu0qf6GK"
      },
      "source": [
        "# Data Ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5DdElWSEl3M"
      },
      "source": [
        "Download dataset from GitHub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462ReJSff9qj",
        "outputId": "db76b88c-aa24-4c25-96d5-188860f468c7"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cialab/neuroendocrine_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiVjbFUX-VOj"
      },
      "source": [
        "Load images and create 64x64 tiles for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE6liSwf5B3g"
      },
      "outputs": [],
      "source": [
        "def load_images_with_masks(image_directory, mask_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_filename in os.listdir(image_directory):\n",
        "        if image_filename.endswith(\".tif\"):\n",
        "            image_filepath = os.path.join(image_directory, image_filename)\n",
        "            mask_filename = image_filename + '.png'\n",
        "            mask_filepath = os.path.join(mask_directory, mask_filename)\n",
        "            try:\n",
        "                image = cv2.imread(image_filepath)\n",
        "                mask = cv2.imread(mask_filepath, cv2.IMREAD_GRAYSCALE)\n",
        "                images.append(image)\n",
        "                labels.append(mask)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {image_filename} or mask: {e}\")\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "def extract_subimages(images, labels, subimage_size=64, step_size=8):\n",
        "    subimages = []\n",
        "    sublabels = []\n",
        "    for i in range(len(images)):\n",
        "        image = images[i]\n",
        "        label = labels[i]\n",
        "        height, width = image.shape[:2]\n",
        "        for y in range(0, height - subimage_size + 1, step_size):\n",
        "            for x in range(0, width - subimage_size + 1, step_size):\n",
        "                subimage = image[y:y+subimage_size, x:x+subimage_size]\n",
        "                sublabel = label[y:y+subimage_size, x:x+subimage_size]\n",
        "                if np.all(sublabel == 0) or np.all(sublabel == 255):\n",
        "                    subimages.append(subimage)\n",
        "                    sublabels.append(sublabel[0][0])  # Assuming all values are the same in the sublabel\n",
        "    return np.array(subimages), np.array(sublabels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM3D4WATgCMJ"
      },
      "source": [
        "### Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8_R6Jjb-Y4H"
      },
      "source": [
        "Create dataset class for training (that resizes images to 299x299, normalize it and convert it to tensor)\n",
        "(Normalization values are taken from the inception-v3 pytorch webpage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlzbPHwe5NIz"
      },
      "outputs": [],
      "source": [
        "# Define a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        imageResize = cv2.resize(image, (299, 299))\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            imageResize = self.transform(imageResize)\n",
        "        return imageResize, label\n",
        "\n",
        "# Define transformations for resizing and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2UqC9ZcqO1o"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEkzPVoAE_cM"
      },
      "source": [
        "Control the training/loading and saving functionalities:\n",
        "\n",
        "- **training**: if yes, performs the computational training of the model. Otherwise, downloads and loads the already trained parameters.\n",
        "- **save**: if yes, saves the current state of the model (regardless of the fact that the training has been performed or not).\n",
        "\n",
        "**Important**: write operations are performed even if files are already present in the runtime. Hence, old files are over-written."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLYEg7HjkI4h"
      },
      "outputs": [],
      "source": [
        "training = False\n",
        "save = False # regardless of the actual training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ftSEphmE8kA"
      },
      "source": [
        "### Training setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWAZXaH3-bm5"
      },
      "source": [
        "Dataset is very unbalanced, so I create a dataset containing 50% tumor and 50% non tumor subimages.\n",
        "I tried to trained on the original unbaiased dataset and the network pretty much always predicted tumor (because in training 90% of subimages are tumor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeL5UU_cF4Ug"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(batch_size=100):\n",
        "\n",
        "  # Replace 'image_directory' and 'mask_directory' with the paths to your image and mask directories\n",
        "  image_directory = 'neuroendocrine_/images'\n",
        "  mask_directory = 'neuroendocrine_/masks'\n",
        "\n",
        "  images, labels = load_images_with_masks(image_directory, mask_directory)\n",
        "  train_images, train_labels = extract_subimages(images[:-1], labels)\n",
        "  val_images, val_labels = extract_subimages(images[-1:], labels)\n",
        "\n",
        "  print(\"Shape of the train_images array:\", train_images.shape)\n",
        "  print(\"Shape of the train_labels array:\", train_labels.shape)\n",
        "  print(\"Shape of the val_images array:\", val_images.shape)\n",
        "  print(\"Shape of the val_labels array:\", val_labels.shape)\n",
        "\n",
        "  # labels should be 0 or 1\n",
        "  train_labels[train_labels == 255] = 1\n",
        "  val_labels[val_labels == 255] = 1\n",
        "\n",
        "  del images\n",
        "  del labels\n",
        "\n",
        "  del val_images\n",
        "  del val_labels\n",
        "\n",
        "  # Assuming train_images and train_labels are your training data\n",
        "  # Calculate the indices of each class\n",
        "  class_0_indices = np.where(train_labels == 0)[0]\n",
        "  class_1_indices = np.where(train_labels == 1)[0]\n",
        "\n",
        "  # Determine the size of the minority class\n",
        "  minority_class_size = len(class_0_indices)\n",
        "\n",
        "  # Randomly sample the same number of samples from the majority class\n",
        "  undersampled_class_1_indices = np.random.choice(class_1_indices, minority_class_size, replace=False)\n",
        "\n",
        "  del class_1_indices\n",
        "  del minority_class_size\n",
        "\n",
        "  # Concatenate the indices of both classes\n",
        "  undersampled_indices = np.concatenate([class_0_indices, undersampled_class_1_indices])\n",
        "\n",
        "  del class_0_indices\n",
        "  del undersampled_class_1_indices\n",
        "\n",
        "  # Shuffle the indices to mix the samples from both classes\n",
        "  np.random.shuffle(undersampled_indices)\n",
        "\n",
        "  # Use the undersampled indices to create a new balanced dataset\n",
        "  undersampled_images = train_images[undersampled_indices]\n",
        "  undersampled_labels = train_labels[undersampled_indices]\n",
        "\n",
        "  del train_images\n",
        "  del train_labels\n",
        "\n",
        "  del undersampled_indices\n",
        "\n",
        "  # Create the undersampled dataset\n",
        "  undersampled_dataset = CustomDataset(undersampled_images, undersampled_labels, transform=transform)\n",
        "\n",
        "  del undersampled_images\n",
        "  del undersampled_labels\n",
        "\n",
        "  # Create the data loader for the undersampled dataset\n",
        "  undersampled_loader = DataLoader(undersampled_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  del undersampled_dataset\n",
        "\n",
        "  return undersampled_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V76STE_w208b"
      },
      "outputs": [],
      "source": [
        "if training == True:\n",
        "\n",
        "  batch_size = 100\n",
        "\n",
        "  undersampled_loader = create_dataloader(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5n6vs6qyHA1"
      },
      "outputs": [],
      "source": [
        "if training == True:\n",
        "\n",
        "  # Set the last fully connected layer to training mode\n",
        "  inceptionv3.fc.train()\n",
        "\n",
        "  # Define loss function and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # optimizer = optim.SGD(inceptionv3.parameters(), lr=0.001, momentum=0.9)\n",
        "  optimizer = optim.Adam(inceptionv3.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agdi_i5HFJsH"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vey35WtfHq1T"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def training_loop(num_epochs=1, max_train=200, print_every=10):\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(undersampled_loader, 1):\n",
        "\n",
        "      # Fetch inputs and labels\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # Initialise gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Feedforward\n",
        "      outputs = inceptionv3(inputs)\n",
        "\n",
        "      # Backpropagate\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "\n",
        "      # Update parameters\n",
        "      optimizer.step()\n",
        "\n",
        "      # Append loss\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "      # Print average loss every print_every iterations\n",
        "      if i % print_every == 0:\n",
        "\n",
        "          epoch_loss = running_loss / (print_every * len(inputs))\n",
        "          print(f\"Iteration [{i}/{len(undersampled_loader)}], Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "          running_loss = 0.0\n",
        "\n",
        "      # Iteration limit\n",
        "      if i >= max_train:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr1aT1B--f-z"
      },
      "source": [
        "Train the network on the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBaT2Sfu5ZY6"
      },
      "outputs": [],
      "source": [
        "if training == True:\n",
        "  # Proceed with the training loop\n",
        "  num_epochs = 1\n",
        "  max_train = 200\n",
        "  print_every = 10\n",
        "\n",
        "  training_loop(num_epochs, max_train, print_every)\n",
        "\n",
        "else:\n",
        "  if os.path.exists(\"incv3_params.pth\"):\n",
        "    params_path = local_path+\"incv3_params.pth\"\n",
        "\n",
        "  else:\n",
        "    params_path = project_path+f\"inception_v3/{model_version}/incv3_params.pth\"\n",
        "\n",
        "  # Load the saved dictionary into your model\n",
        "  state_dict = torch.load(params_path, map_location=device)\n",
        "  inceptionv3.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eYQlZXwyNSQ"
      },
      "outputs": [],
      "source": [
        "if save == True:\n",
        "   torch.save(inceptionv3.state_dict(), local_path+\"incv3_params.pth\") # save the model state after the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3peaDDzFuBG"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skf84y9hyK93"
      },
      "source": [
        "Control the prediction/loading and writing functionalities:\n",
        "\n",
        "- **pred**: if yes, performs the computational prediction of a selected image's segmentation. Otherwise, loads the file avg.png from the Colab runtime (if it is not present, it downloads it from th GitHub project's repo).\n",
        "- **avg_write**: if yes, write to the Colab runtime the raw output of the model based on the chosen image (regardless of the fact that the computation has been performed or not).\n",
        "- **output_write**: if yes, write to the Colab runtime the thresholded output of the model based on the chosen image (regardless of the fact that the computation has been performed or not).\n",
        "\n",
        "**Important**: write operations are performed even if files are already present in the runtime. Hence, old files are over-written."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuTlfX5NyG0a"
      },
      "outputs": [],
      "source": [
        "pred = False # If true, predict the mask of a chosen image; otherwise, consider the already predicted photo\n",
        "avg_write = False # Write the avg photo to Colab, regardless of the actual computation or not\n",
        "output_write = False # Write the final output photo to Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOmTz-XwPk0p"
      },
      "outputs": [],
      "source": [
        "img_idx = -1 # index of image chosen for evaluation (loaded avg.png refers to -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXjGsp9HkVVD"
      },
      "source": [
        "Access input images directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFd6y5dxkd-H"
      },
      "outputs": [],
      "source": [
        "images_dir_path = Path(dataset_path+\"images\")\n",
        "\n",
        "# List all files in the folder\n",
        "images_paths = sorted(list(images_dir_path.iterdir()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEmkDWDIkYP-"
      },
      "source": [
        "Access mask images directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0iv1xWSQJ3O"
      },
      "outputs": [],
      "source": [
        "masks_dir_path = Path(dataset_path+\"masks\")\n",
        "\n",
        "# List all masks in the directory\n",
        "masks_paths = sorted(list(masks_dir_path.iterdir()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5q6CW5HkzRP"
      },
      "source": [
        "Evaluated photo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkiPlvMCky14",
        "outputId": "41108cb1-821c-42fd-ce80-33653ec9d651"
      },
      "outputs": [],
      "source": [
        "images_paths[img_idx], masks_paths[img_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cM26m0sPfQ6"
      },
      "source": [
        "### Target visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "tc1e9BQxSirB",
        "outputId": "b88c446f-3df6-420d-aa4b-955ec416a2fc"
      },
      "outputs": [],
      "source": [
        "testImage = cv2.imread(str(images_paths[img_idx]))\n",
        "testMask = cv2.imread(str(masks_paths[img_idx]))\n",
        "\n",
        "plt.imshow(testImage)\n",
        "plt.imshow(testMask, alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2jtjskvQ89b"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP0pkw-q-jO6"
      },
      "source": [
        "Use selected image for testing. Create 64x64 tiles and feed them to the network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwjbgI4EkAPQ"
      },
      "outputs": [],
      "source": [
        "def predict(image):\n",
        "\n",
        "  # Assuming 'images' is your list of images and 'testImage' is one such image\n",
        "  # testImage = cv2.imread('/content/neuroendocrine_/images/HotSpot43_3.tif')\n",
        "  testImage = image\n",
        "\n",
        "  subimage_size = 64\n",
        "  step_size = 8\n",
        "\n",
        "  height, width = testImage.shape[:2]\n",
        "  outputHeight = height - height % step_size\n",
        "  outputWidth = width - width % step_size\n",
        "  tumorCount = np.zeros((outputHeight, outputWidth))\n",
        "  count = np.zeros((outputHeight, outputWidth))\n",
        "\n",
        "  # Move model to GPU\n",
        "  inceptionv3.eval()\n",
        "\n",
        "  for row in range(0, height - subimage_size + 1, step_size):\n",
        "      if row % 50 == 0:\n",
        "          print('Row ' + str(row) + '/ ' + str(height))\n",
        "      for col in range(0, width - subimage_size + 1, step_size):\n",
        "          subimage = testImage[row:row+subimage_size, col:col+subimage_size]\n",
        "\n",
        "          # Prepare subimage for InceptionV3\n",
        "          # Resize the subimage using OpenCV\n",
        "          resized_subimage = cv2.resize(subimage, (299, 299))\n",
        "\n",
        "          # Define the transformations\n",
        "          transform = transforms.Compose([\n",
        "              transforms.ToTensor(),  # Convert image to tensor\n",
        "              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
        "          ])\n",
        "\n",
        "          # Apply the transformations and move to GPU\n",
        "          transformed_subimage = transform(resized_subimage).to(device)\n",
        "\n",
        "          # Compute output on GPU\n",
        "          with torch.no_grad():\n",
        "              output = inceptionv3(transformed_subimage.unsqueeze(0))\n",
        "              label = torch.argmax(output)\n",
        "\n",
        "          # Write to matrix\n",
        "          if label == 1:\n",
        "              tumorCount[row:row+subimage_size, col:col+subimage_size] += 1\n",
        "          count[row:row+subimage_size, col:col+subimage_size] += 1\n",
        "\n",
        "  # Calculate average tumor occurrence per submatrix\n",
        "  avg = np.divide(tumorCount, count)\n",
        "\n",
        "  return avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kgU3zU9rGXe"
      },
      "source": [
        "Mask prediction computation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSqLtGsArOnp"
      },
      "outputs": [],
      "source": [
        "if pred == True:\n",
        "  avg = predict(testImage)\n",
        "\n",
        "else:\n",
        "  # Download avg.png\n",
        "  if os.path.exists(\"avg.png\"):\n",
        "    avg_path = local_path+\"avg.png\"\n",
        "\n",
        "  else:\n",
        "    avg_path = project_path+f\"/inception_v3/{model_version}/avg.png\"\n",
        "\n",
        "  avg = cv2.imread(avg_path)\n",
        "\n",
        "  # Convert the image to grayscale\n",
        "  avg = cv2.cvtColor(avg, cv2.COLOR_BGR2GRAY)\n",
        "  avg = avg/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55lVXOzfyNST"
      },
      "outputs": [],
      "source": [
        "if avg_write == True:\n",
        "   cv2.imwrite('avg.png', avg*255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nydkmUxI-mjo"
      },
      "source": [
        "Raw output of the segmentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "LBd5-JLLDBC0",
        "outputId": "4b096861-9e0f-4e0c-f47b-38232a0199f2"
      },
      "outputs": [],
      "source": [
        "printAvg = avg*255\n",
        "\n",
        "# Displaying the numpy array as grayscale\n",
        "plt.imshow(printAvg, cmap='gray', vmin=0, vmax=255)  # Specify vmin and vmax\n",
        "plt.axis('off')  # Turn off axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhyT_7bV-otp"
      },
      "source": [
        "Thresholded prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "NRsO84VjB3Y1",
        "outputId": "2eebcfdf-720a-484e-e98e-ca6e97e5aa35"
      },
      "outputs": [],
      "source": [
        "thr = 0.5 # threshold\n",
        "\n",
        "modelGuess = np.where(avg >= thr, 255, 0).astype(np.uint8)[:1283, :2040]\n",
        "\n",
        "# Displaying the numpy array as grayscale\n",
        "plt.imshow(modelGuess, cmap='gray', vmin=0, vmax=255)  # Specify vmin and vmax\n",
        "plt.axis('off')  # Turn off axis\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWQbNhbPd74o"
      },
      "source": [
        "Output saving:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a63MDDvPyD-W"
      },
      "outputs": [],
      "source": [
        "if output_write == True:\n",
        "  cv2.imwrite('output_image.png', modelGuess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYqY8-YEdKlv"
      },
      "source": [
        "### Classification metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZeQrFF4Tqag"
      },
      "outputs": [],
      "source": [
        "def pixel_accuracy(y_true, y_pred):\n",
        "\n",
        "  return accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "\n",
        "def pixel_precision(y_true, y_pred):\n",
        "\n",
        "  true_positives = np.sum(np.logical_and(y_true, y_pred))\n",
        "  false_positives = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
        "\n",
        "  if true_positives + false_positives == 0:\n",
        "      return 0.0\n",
        "  else:\n",
        "      return true_positives / (true_positives + false_positives)\n",
        "\n",
        "def pixel_recall(y_true, y_pred):\n",
        "\n",
        "  true_positives = np.sum(np.logical_and(y_true, y_pred))\n",
        "  false_negatives = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
        "\n",
        "  if true_positives + false_negatives == 0:\n",
        "      return 0.0\n",
        "  else:\n",
        "      return true_positives / (true_positives + false_negatives)\n",
        "\n",
        "def intersection_over_union(y_true, y_pred):\n",
        "\n",
        "  intersection = np.logical_and(y_true, y_pred)\n",
        "  union = np.logical_or(y_true, y_pred)\n",
        "  return np.sum(intersection) / np.sum(union)\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "\n",
        "  intersection = np.logical_and(y_true, y_pred)\n",
        "\n",
        "  return 2.0 * np.sum(intersection) / (np.sum(y_true) + np.sum(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcJM2Jdgbbap"
      },
      "outputs": [],
      "source": [
        "y_true = (modelGuess/255).astype(bool)\n",
        "y_pred = (testMask[:,:,0]/255).astype(bool)\n",
        "\n",
        "pos = True # True: tumor, False: non-tumor\n",
        "\n",
        "if pos == False:\n",
        "  y_true = np.logical_not(y_true)\n",
        "  y_pred = np.logical_not(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoC9uBq4Tuia"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "acc = pixel_accuracy(y_true, y_pred)\n",
        "prec = pixel_precision(y_true, y_pred)\n",
        "recall = pixel_recall(y_true, y_pred)\n",
        "iou = intersection_over_union(y_true, y_pred)\n",
        "dice = dice_coefficient(y_true, y_pred)\n",
        "\n",
        "# Organize the metrics into a list of lists\n",
        "metrics_table = [\n",
        "    [\"Pixel Accuracy\", f\"{acc:0.4f}\"],\n",
        "    [\"Pixel Precision\", f\"{prec:0.4f}\"],\n",
        "    [\"Pixel Recall\", f\"{recall:0.4f}\"],\n",
        "    [\"IoU\", f\"{iou:0.4f}\"],\n",
        "    [\"Dice Coeff.\", f\"{dice:0.4f}\"]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiRfIPvBd0er",
        "outputId": "0e342c38-b853-4567-f565-28ff37d665ec"
      },
      "outputs": [],
      "source": [
        "# Display the metrics table\n",
        "print(tabulate(metrics_table, headers=[\"Metric\", \"Value\"], tablefmt=\"grid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBwpRGKCHx8b"
      },
      "source": [
        "### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nQhZ_CFGIT3"
      },
      "outputs": [],
      "source": [
        "# Assuming modelGuess and testMask are your predicted and actual values respectively\n",
        "conf_matrix = confusion_matrix(y_true.flatten(), y_pred.flatten())\n",
        "conf_norm_matrix = confusion_matrix(y_true.flatten(), y_pred.flatten(), normalize=\"true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "UJ5wmqdxHVFC",
        "outputId": "499367ec-b495-45e9-8371-7e69ef0d09e8"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
        "\n",
        "text = \"\"\"\n",
        "- 0: non-tumor pixel\n",
        "- 1: tumor pixel\n",
        "\"\"\"\n",
        "\n",
        "fig.text(0.5, 0.90, text, ha='center', fontsize=16, color='black')\n",
        "\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5, square=True, ax=axs[0])\n",
        "axs[0].set_title(\"Confusion matrix\")\n",
        "axs[0].set_xlabel(\"Predicted label\")\n",
        "axs[0].set_ylabel(\"True label\")\n",
        "\n",
        "sns.heatmap(conf_norm_matrix, annot=True, fmt=\".2%\", cmap=\"Blues\", linewidths=.5, square=True, ax=axs[1])\n",
        "axs[1].set_title(\"Confusion normalised matrix\")\n",
        "axs[1].set_xlabel(\"Predicted label\")\n",
        "axs[1].set_ylabel(\"True label\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz8vs6D6Sgba"
      },
      "source": [
        "### Visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6Tq8uz03XsZ"
      },
      "source": [
        "Visualisation of prediction border onto input image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qZytk6jnNjH"
      },
      "outputs": [],
      "source": [
        "# Define the disk structuring element\n",
        "radius = 2\n",
        "disk_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "\n",
        "# Apply erosion using the disk structuring element\n",
        "eroded_mask = cv2.erode(modelGuess, disk_kernel)\n",
        "\n",
        "tumorBorder = modelGuess - eroded_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "Dn2HkVPYnXse",
        "outputId": "54d1f32a-958c-4001-e996-098f02df4c58"
      },
      "outputs": [],
      "source": [
        "map_rgb = cv2.cvtColor(tumorBorder, cv2.COLOR_GRAY2RGB)\n",
        "alpha = 0.5  # Adjust the transparency of the overlaid image\n",
        "overlay = cv2.addWeighted(testImage[:1283, :2040], alpha, map_rgb, 1 - alpha, 0)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
